{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d39d045fd3f64722bf4e5b14138527a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ba3649643724cbe962b443214daef48",
              "IPY_MODEL_0472312d25c44e31b531e366289f1d71",
              "IPY_MODEL_dfbf07fcacda4a6ea11249a7fa8e98ce"
            ],
            "layout": "IPY_MODEL_4c9f916d0f78443a9c180b5dced7e4cc"
          }
        },
        "9ba3649643724cbe962b443214daef48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25aac847e779447b88c81b162bf48974",
            "placeholder": "​",
            "style": "IPY_MODEL_95ac3bbd47e4445ab162b584114ca2c1",
            "value": "modules.json: 100%"
          }
        },
        "0472312d25c44e31b531e366289f1d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c113ddc78c469eaa6bad4009c01770",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_592bd3ff49b44d77b8414c2edab05be9",
            "value": 349
          }
        },
        "dfbf07fcacda4a6ea11249a7fa8e98ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796886f682044fce91e51e44d30765a0",
            "placeholder": "​",
            "style": "IPY_MODEL_8177258ca0e947319dec02aeae5b6381",
            "value": " 349/349 [00:00&lt;00:00, 17.2kB/s]"
          }
        },
        "4c9f916d0f78443a9c180b5dced7e4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25aac847e779447b88c81b162bf48974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ac3bbd47e4445ab162b584114ca2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2c113ddc78c469eaa6bad4009c01770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592bd3ff49b44d77b8414c2edab05be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "796886f682044fce91e51e44d30765a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8177258ca0e947319dec02aeae5b6381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e97128ea1c744f4b9c6195a0f22d2329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df029d689cec4b02ba1a316ccdf97e3e",
              "IPY_MODEL_a0a054dd486f4bd19c692d851af37d1c",
              "IPY_MODEL_a200be6a31cb4ca98482722d1134dbb9"
            ],
            "layout": "IPY_MODEL_b8d908d32694456a8e1eaa008623ac63"
          }
        },
        "df029d689cec4b02ba1a316ccdf97e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f8fa5e157e4cff898d698f257fc0de",
            "placeholder": "​",
            "style": "IPY_MODEL_f4c27ae844c44b8188a80d54a2d85f06",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "a0a054dd486f4bd19c692d851af37d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a8fb2b3f94d4eb79fbcf25912c9655a",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcbe119185de40eaaf7c684ea67f3d14",
            "value": 116
          }
        },
        "a200be6a31cb4ca98482722d1134dbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21a16457eda4bb4b5e7ca91d6f3e10e",
            "placeholder": "​",
            "style": "IPY_MODEL_16f6532f1be5458abfcbea7b24d4bf80",
            "value": " 116/116 [00:00&lt;00:00, 6.21kB/s]"
          }
        },
        "b8d908d32694456a8e1eaa008623ac63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f8fa5e157e4cff898d698f257fc0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c27ae844c44b8188a80d54a2d85f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a8fb2b3f94d4eb79fbcf25912c9655a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbe119185de40eaaf7c684ea67f3d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21a16457eda4bb4b5e7ca91d6f3e10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f6532f1be5458abfcbea7b24d4bf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83370e1f6bfe4838980ac4152b0e87ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1cb8e66dccd46f594d47dd1c5fb3c96",
              "IPY_MODEL_4e2b497a4af5446b8ad9c79362e270d7",
              "IPY_MODEL_b9f3b733c26f479eb92f3122100c502b"
            ],
            "layout": "IPY_MODEL_99eb1b39eb344dfeb4cadced9160f96b"
          }
        },
        "b1cb8e66dccd46f594d47dd1c5fb3c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcaa19f7713f4caf9e17fdbdc43217c5",
            "placeholder": "​",
            "style": "IPY_MODEL_06dbb888be494c7f8fa4c438a115140e",
            "value": "README.md: 100%"
          }
        },
        "4e2b497a4af5446b8ad9c79362e270d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0dd86dc738e4432b5459f35f7549df1",
            "max": 10341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc2fc3cbb85544079c07458ad199cee5",
            "value": 10341
          }
        },
        "b9f3b733c26f479eb92f3122100c502b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8510667c3d6b4830a2953fc2ccaa0866",
            "placeholder": "​",
            "style": "IPY_MODEL_6a5ce7573dc24e839b4ce45783df8eb9",
            "value": " 10.3k/10.3k [00:00&lt;00:00, 685kB/s]"
          }
        },
        "99eb1b39eb344dfeb4cadced9160f96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcaa19f7713f4caf9e17fdbdc43217c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dbb888be494c7f8fa4c438a115140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0dd86dc738e4432b5459f35f7549df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2fc3cbb85544079c07458ad199cee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8510667c3d6b4830a2953fc2ccaa0866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5ce7573dc24e839b4ce45783df8eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de7a747a47b1496db0a2bfd31651f2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_056b9056c77e485b93c0c24b48e1748d",
              "IPY_MODEL_a5b7db3b01ff4ae5a3aa5f21841735b7",
              "IPY_MODEL_1c02991d5569466bb3fc88634870b806"
            ],
            "layout": "IPY_MODEL_7ce0c9af26234b76b3f5e265445dc1b8"
          }
        },
        "056b9056c77e485b93c0c24b48e1748d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9648c2297f47309bdf1e967ff013cf",
            "placeholder": "​",
            "style": "IPY_MODEL_018ede14e82f45b59fcbd71f8dfb38b7",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "a5b7db3b01ff4ae5a3aa5f21841735b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233a7e0ad28348289f5dd204e74fb8cd",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0adf3900c54e4b3eb4ef71fd552232a6",
            "value": 53
          }
        },
        "1c02991d5569466bb3fc88634870b806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81609093f0ad4348a267f884f2a8dc80",
            "placeholder": "​",
            "style": "IPY_MODEL_063f7f57bfd44c5daa37d1b7dd39582a",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.89kB/s]"
          }
        },
        "7ce0c9af26234b76b3f5e265445dc1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd9648c2297f47309bdf1e967ff013cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018ede14e82f45b59fcbd71f8dfb38b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233a7e0ad28348289f5dd204e74fb8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0adf3900c54e4b3eb4ef71fd552232a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81609093f0ad4348a267f884f2a8dc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063f7f57bfd44c5daa37d1b7dd39582a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e4ee443e66145429dc0856d9c317801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4c44a438cae49ae93327116b87e4bcc",
              "IPY_MODEL_dab3c970a56b4f138a08c7425896d3eb",
              "IPY_MODEL_d8aff408454a4d0f926f963b6f614277"
            ],
            "layout": "IPY_MODEL_fa157c2d29454a1a85567239f29c7a28"
          }
        },
        "f4c44a438cae49ae93327116b87e4bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4788af94ec4745b43c18028bbec2bd",
            "placeholder": "​",
            "style": "IPY_MODEL_9867a0e1afb945589c8f46128dee7bb1",
            "value": "config.json: 100%"
          }
        },
        "dab3c970a56b4f138a08c7425896d3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d68cc2250844acea1bb8a9ddecd2310",
            "max": 653,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bddcf2133c748b8804ae1e26bf8cc04",
            "value": 653
          }
        },
        "d8aff408454a4d0f926f963b6f614277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86dc72308df4e6ca0b10c55c0865356",
            "placeholder": "​",
            "style": "IPY_MODEL_e693b089718f40cabaae895ed46c3acb",
            "value": " 653/653 [00:00&lt;00:00, 23.6kB/s]"
          }
        },
        "fa157c2d29454a1a85567239f29c7a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4788af94ec4745b43c18028bbec2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9867a0e1afb945589c8f46128dee7bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d68cc2250844acea1bb8a9ddecd2310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bddcf2133c748b8804ae1e26bf8cc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f86dc72308df4e6ca0b10c55c0865356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e693b089718f40cabaae895ed46c3acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bc1371c8d294e69ace3092ca538ba23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66eee02281d84bbd9a1ed1972838b7bd",
              "IPY_MODEL_59237527f49c42dab1cc17591d56c5b0",
              "IPY_MODEL_e492d5fcdac04945abe5c933e2b5325e"
            ],
            "layout": "IPY_MODEL_855ab17a8955491f954a53183dafe3d2"
          }
        },
        "66eee02281d84bbd9a1ed1972838b7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2348bf1fb3074850ac60c7fff1bf8c23",
            "placeholder": "​",
            "style": "IPY_MODEL_40132b132a1d46919cfc6726cd18a312",
            "value": "model.safetensors: 100%"
          }
        },
        "59237527f49c42dab1cc17591d56c5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1b4b18b5eec4fea8238efa368f7b243",
            "max": 328489328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_000bd9cbd34e4e1d818f47a267ea7241",
            "value": 328489328
          }
        },
        "e492d5fcdac04945abe5c933e2b5325e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8e5a032e9f84d76b12e904ff6d2bb29",
            "placeholder": "​",
            "style": "IPY_MODEL_3cd4882c7e3a4cf3a44a2dd8c6826345",
            "value": " 328M/328M [00:02&lt;00:00, 148MB/s]"
          }
        },
        "855ab17a8955491f954a53183dafe3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2348bf1fb3074850ac60c7fff1bf8c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40132b132a1d46919cfc6726cd18a312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1b4b18b5eec4fea8238efa368f7b243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000bd9cbd34e4e1d818f47a267ea7241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8e5a032e9f84d76b12e904ff6d2bb29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd4882c7e3a4cf3a44a2dd8c6826345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4c862eec254f9890e09b94f63954d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36f5a26d670d45e5bff6e66947c03d69",
              "IPY_MODEL_a9c1e87100c44873980e6e530cac973b",
              "IPY_MODEL_987cafa6e985497486d896b7bc903781"
            ],
            "layout": "IPY_MODEL_41599fcd3aa647f5905d9c68f4209204"
          }
        },
        "36f5a26d670d45e5bff6e66947c03d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca40a10feedb4f0db8601ec483ac28d3",
            "placeholder": "​",
            "style": "IPY_MODEL_1881f0c1071a4b42b2b85a7d75af4b4d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a9c1e87100c44873980e6e530cac973b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a384a1eec248df9d839021bc98183a",
            "max": 333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9eb62516a5046098dd8d9ece786f9d4",
            "value": 333
          }
        },
        "987cafa6e985497486d896b7bc903781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70dc0e8014de4105b4a7cfc6fcf00fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_cf34dbf1d2ca410fb52259f559c6a22d",
            "value": " 333/333 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "41599fcd3aa647f5905d9c68f4209204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca40a10feedb4f0db8601ec483ac28d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1881f0c1071a4b42b2b85a7d75af4b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86a384a1eec248df9d839021bc98183a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9eb62516a5046098dd8d9ece786f9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70dc0e8014de4105b4a7cfc6fcf00fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf34dbf1d2ca410fb52259f559c6a22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4c8f91b16042ccbd48047a43a4b52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31ddc07c2cbe4977a58d32877b9b46ff",
              "IPY_MODEL_02a3d75d1678401fa6afb7b0dcd89a42",
              "IPY_MODEL_581ce0e5b6c240debf57aa3e1f79f9ca"
            ],
            "layout": "IPY_MODEL_a526573623274971a5dc8d0b9c5bb231"
          }
        },
        "31ddc07c2cbe4977a58d32877b9b46ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a89500b9f94a69a7ae3d8b7f5d61b3",
            "placeholder": "​",
            "style": "IPY_MODEL_328bcbf1a64949fd856a4b926fd8e943",
            "value": "vocab.json: 100%"
          }
        },
        "02a3d75d1678401fa6afb7b0dcd89a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e51b834887b4b1a8d59802b65010187",
            "max": 798293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a41cd674999e48ec8b90c2ca89d34e3e",
            "value": 798293
          }
        },
        "581ce0e5b6c240debf57aa3e1f79f9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85f125394d464db6bf16db218662974c",
            "placeholder": "​",
            "style": "IPY_MODEL_454b6f55f4ad4e6c910aa963ad01f02c",
            "value": " 798k/798k [00:00&lt;00:00, 4.96MB/s]"
          }
        },
        "a526573623274971a5dc8d0b9c5bb231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a89500b9f94a69a7ae3d8b7f5d61b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328bcbf1a64949fd856a4b926fd8e943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e51b834887b4b1a8d59802b65010187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41cd674999e48ec8b90c2ca89d34e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85f125394d464db6bf16db218662974c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454b6f55f4ad4e6c910aa963ad01f02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dddc14a237fb4b448bc1170dca27e8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a55272a6a6e4bbe88bd8733d7e193c1",
              "IPY_MODEL_3b35e458e8f3474c9f28af44a8991d45",
              "IPY_MODEL_295cbfaded904d2c94761a5a0edbc4d7"
            ],
            "layout": "IPY_MODEL_c3b1b6dfa24e4a7aa4399da6b0bf369b"
          }
        },
        "6a55272a6a6e4bbe88bd8733d7e193c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e053d6d71ac4184861a3bf110c11fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_e7521ffb84804b0c8675055460e14190",
            "value": "merges.txt: 100%"
          }
        },
        "3b35e458e8f3474c9f28af44a8991d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b4bc16b1874c39bbcc0e1a527504ff",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e067c79cd8364328b1496acdeef19028",
            "value": 456356
          }
        },
        "295cbfaded904d2c94761a5a0edbc4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c548b7c7fa3b4923978b289ab9f60810",
            "placeholder": "​",
            "style": "IPY_MODEL_8d2d820f5c3d4028a174f3c77e6e68c4",
            "value": " 456k/456k [00:00&lt;00:00, 17.0MB/s]"
          }
        },
        "c3b1b6dfa24e4a7aa4399da6b0bf369b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e053d6d71ac4184861a3bf110c11fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7521ffb84804b0c8675055460e14190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0b4bc16b1874c39bbcc0e1a527504ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e067c79cd8364328b1496acdeef19028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c548b7c7fa3b4923978b289ab9f60810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2d820f5c3d4028a174f3c77e6e68c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ab1a984167473290d19fcb13f53ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0abdbb7f9fee4af4b8f104818b47688d",
              "IPY_MODEL_0dd4c34db73d476fb623e50bc8fae75d",
              "IPY_MODEL_b3100a3128064e0a8833312b6d8e1bf0"
            ],
            "layout": "IPY_MODEL_55885dcc834140eeab1d93fe64651d87"
          }
        },
        "0abdbb7f9fee4af4b8f104818b47688d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c350797e824b40928593008f35310af8",
            "placeholder": "​",
            "style": "IPY_MODEL_851bac6195024b6681ff3a634fe2bc5d",
            "value": "tokenizer.json: 100%"
          }
        },
        "0dd4c34db73d476fb623e50bc8fae75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c70326deb6648909ef79061b314a540",
            "max": 1356047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e279140510294dcfb7359876edf745a9",
            "value": 1356047
          }
        },
        "b3100a3128064e0a8833312b6d8e1bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce76c8f6605d4581bb5e92658fdb030a",
            "placeholder": "​",
            "style": "IPY_MODEL_8b83af9dcedb42fc89ce95487490ba0b",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 22.7MB/s]"
          }
        },
        "55885dcc834140eeab1d93fe64651d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c350797e824b40928593008f35310af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851bac6195024b6681ff3a634fe2bc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c70326deb6648909ef79061b314a540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e279140510294dcfb7359876edf745a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce76c8f6605d4581bb5e92658fdb030a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b83af9dcedb42fc89ce95487490ba0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e05ad41957241acb2fef1fa678f3e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff0ebcfa4ebd4aea9fe89aa14d2808ef",
              "IPY_MODEL_3601780dfa1e4d07a728daf016e5b0bc",
              "IPY_MODEL_e7a1bef43219477ba33872d55d1514b0"
            ],
            "layout": "IPY_MODEL_5f4030a409f745bd94b38faf12da367f"
          }
        },
        "ff0ebcfa4ebd4aea9fe89aa14d2808ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51dbe1ac99b42b8bc25d965a123e31b",
            "placeholder": "​",
            "style": "IPY_MODEL_7994e8a4c7c847289e43f6a7111a5041",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3601780dfa1e4d07a728daf016e5b0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077b5f4e6e294b588a4a3007a6fdd185",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c365b97fbc254ab583d529551fff4f2b",
            "value": 239
          }
        },
        "e7a1bef43219477ba33872d55d1514b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb2d0dc3e4d42608012072929c2a612",
            "placeholder": "​",
            "style": "IPY_MODEL_67c7c2f95be94744b5ca3e93e3390cd7",
            "value": " 239/239 [00:00&lt;00:00, 12.3kB/s]"
          }
        },
        "5f4030a409f745bd94b38faf12da367f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51dbe1ac99b42b8bc25d965a123e31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7994e8a4c7c847289e43f6a7111a5041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077b5f4e6e294b588a4a3007a6fdd185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c365b97fbc254ab583d529551fff4f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fb2d0dc3e4d42608012072929c2a612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c7c2f95be94744b5ca3e93e3390cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6de7eef381b343d9985a85179043e671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5819f825276a4e0f9e792d0b5fb0e565",
              "IPY_MODEL_ca91168e72b94b9fa7180f34c373827f",
              "IPY_MODEL_c5e6f739c3c74ad782bee756b6b72c25"
            ],
            "layout": "IPY_MODEL_9a74a1bc48be423f94ceef5a43226077"
          }
        },
        "5819f825276a4e0f9e792d0b5fb0e565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d76cd7ae864cd1bf14101dddfbaadc",
            "placeholder": "​",
            "style": "IPY_MODEL_8fce4dfa34664b40a261be0e3e1b9e14",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "ca91168e72b94b9fa7180f34c373827f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b3d49abefb4975a30627068a77d444",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e7abc4343444cd0840db3615282217b",
            "value": 190
          }
        },
        "c5e6f739c3c74ad782bee756b6b72c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078490d9657b4cca90414a0b5b831928",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d4eded1dac4ab69ee9cb2f6544f58d",
            "value": " 190/190 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "9a74a1bc48be423f94ceef5a43226077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d76cd7ae864cd1bf14101dddfbaadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fce4dfa34664b40a261be0e3e1b9e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b3d49abefb4975a30627068a77d444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7abc4343444cd0840db3615282217b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "078490d9657b4cca90414a0b5b831928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d4eded1dac4ab69ee9cb2f6544f58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oO7ancW_dXET",
        "outputId": "7dd36f0b-31c6-440d-da25-8da72413ae26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-agentchat~=0.2 (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading autogen_agentchat-0.2.40-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting flaml[automl]\n",
            "  Downloading FLAML-2.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting diskcache (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.57.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (24.2)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.10.3)\n",
            "Collecting python-dotenv (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.5.0)\n",
            "Collecting tiktoken (from autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from flaml[automl]) (4.5.0)\n",
            "Requirement already satisfied: xgboost<3.0.0,>=0.90 in /usr/local/lib/python3.10/dist-packages (from flaml[automl]) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from flaml[automl]) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from flaml[automl]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flaml[automl]) (1.6.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat[retrievechat-qdrant]~=0.2) (4.12.3)\n",
            "Collecting chromadb (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastembed>=0.3.1 (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading fastembed-0.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat[retrievechat-qdrant]~=0.2) (7.34.0)\n",
            "Collecting markdownify (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting protobuf==4.25.3 (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pypdf (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting qdrant-client (from autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat[retrievechat-qdrant]~=0.2) (3.3.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.10/dist-packages (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.27.0)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting onnx>=1.15.0 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading py_rust_stemmers-0.1.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.10/dist-packages (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.21.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.10/dist-packages (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->flaml[automl]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->flaml[automl]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->flaml[automl]) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.27.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->flaml[automl]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->flaml[automl]) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost<3.0.0,>=0.90->flaml[automl]) (2.23.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.6)\n",
            "Collecting build>=1.0.3 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.29.0)\n",
            "Collecting tokenizers<1.0,>=0.15 (from fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (6.0.2)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.10.12)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (13.9.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.2.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (4.9.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.10/dist-packages (from markdownify->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.17.0)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.2.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.2.1)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading grpcio_tools-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (2024.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.8.4)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.7.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.4.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (4.9)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.3.1->autogen-agentchat[retrievechat-qdrant]~=0.2)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->autogen-agentchat[retrievechat-qdrant]~=0.2) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->autogen-agentchat[retrievechat-qdrant]~=0.2) (0.6.1)\n",
            "Downloading autogen_agentchat-0.2.40-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.3/382.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastembed-0.5.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.3-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.2/314.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading qdrant_client-1.12.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_rust_stemmers-0.1.3-cp310-cp310-manylinux_2_28_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=2486ddd385304f4f9cd0d72859c59db14d67c003ea2ca5824ee737f252c1f4c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, py-rust-stemmers, monotonic, mmh3, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, pypdf, protobuf, portalocker, pillow, overrides, opentelemetry-util-http, loguru, jedi, importlib-metadata, hyperframe, humanfriendly, httptools, hpack, flaml, diskcache, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-proto, opentelemetry-api, onnx, markdownify, h2, grpcio-tools, docker, coloredlogs, build, tokenizers, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, transformers, qdrant-client, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastembed, autogen-agentchat, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.29.0\n",
            "    Uninstalling opentelemetry-api-1.29.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.29.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.50b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.50b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.50b0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.29.0\n",
            "    Uninstalling opentelemetry-sdk-1.29.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.29.0\n",
            "Successfully installed asgiref-3.8.1 autogen-agentchat-0.2.40 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 diskcache-5.6.3 docker-7.1.0 durationpy-0.9 fastapi-0.115.6 fastembed-0.5.0 flaml-2.3.3 grpcio-tools-1.62.3 h2-4.1.0 hpack-4.0.0 httptools-0.6.4 humanfriendly-10.0 hyperframe-6.0.1 importlib-metadata-8.4.0 jedi-0.19.2 kubernetes-31.0.0 loguru-0.7.3 markdownify-0.14.1 mmh3-4.1.0 monotonic-1.6 onnx-1.17.0 onnxruntime-1.20.1 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 pillow-10.4.0 portalocker-2.10.1 posthog-3.7.4 protobuf-4.25.3 py-rust-stemmers-0.1.3 pypdf-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 qdrant-client-1.12.2 starlette-0.41.3 tiktoken-0.8.0 tokenizers-0.20.3 transformers-4.46.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "importlib_metadata"
                ]
              },
              "id": "34c6d33d9b014d82b306cace159f24c2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"autogen-agentchat[retrievechat-qdrant]~=0.2\" \"flaml[automl]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('open_ai')\n",
        "config=[\n",
        "    {\n",
        "        \"model\": \"gpt-4-turbo-preview\",\n",
        "        \"api_key\":api_key\n",
        "    }\n",
        "]\n",
        "with open(\"OAI_CONFIG_LIST\", \"w\") as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "config_list = autogen.config_list_from_json(\"OAI_CONFIG_LIST\")"
      ],
      "metadata": {
        "id": "71ePUeoPdYl_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import autogen\n",
        "from autogen import AssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "\n",
        "# Accepted file formats for that can be stored in\n",
        "# a vector database instance\n",
        "from autogen.retrieve_utils import TEXT_FORMATS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n16l8oKMd6c4",
        "outputId": "ea25f76e-6d44-44da-8a10-dcfcf0f1419d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accepted file formats for `docs_path`:\")\n",
        "print(TEXT_FORMATS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf3noKLcfucI",
        "outputId": "e18575e6-1089-4f92-96fd-60a0983ba038"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accepted file formats for `docs_path`:\n",
            "['txt', 'json', 'csv', 'tsv', 'md', 'html', 'htm', 'rtf', 'rst', 'jsonl', 'log', 'xml', 'yaml', 'yml', 'pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. create an AssistantAgent instance named \"assistant\"\n",
        "assistant = AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    system_message=\"You are a helpful assistant.\",\n",
        "    llm_config={\n",
        "        \"timeout\": 600,\n",
        "        \"cache_seed\": 42,\n",
        "        \"config_list\": config_list,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Optionally create embedding function object\n",
        "sentence_transformer_ef = SentenceTransformer(\"all-distilroberta-v1\").encode\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
        "# Refer to https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_user_proxy_agent\n",
        "# and https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/vectordb/qdrant\n",
        "# for more information on the RetrieveUserProxyAgent and QdrantVectorDB\n",
        "ragproxyagent = RetrieveUserProxyAgent(\n",
        "    name=\"ragproxyagent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    retrieve_config={\n",
        "        \"task\": \"code\",\n",
        "        \"docs_path\": [\n",
        "            \"https://raw.githubusercontent.com/microsoft/flaml/main/README.md\",\n",
        "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n",
        "        ],  # change this to your own path, such as https://raw.githubusercontent.com/microsoft/autogen/main/README.md\n",
        "        \"chunk_token_size\": 2000,\n",
        "        \"model\": config_list[0][\"model\"],\n",
        "        \"db_config\": {\"client\": client},\n",
        "        \"vector_db\": \"qdrant\",  # qdrant database\n",
        "        \"get_or_create\": True,  # set to False if you don't want to reuse an existing collection\n",
        "        \"overwrite\": True,  # set to True if you want to overwrite an existing collection\n",
        "        \"embedding_function\": sentence_transformer_ef,  # If left out fastembed \"BAAI/bge-small-en-v1.5\" will be used\n",
        "    },\n",
        "    code_execution_config=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "d39d045fd3f64722bf4e5b14138527a7",
            "9ba3649643724cbe962b443214daef48",
            "0472312d25c44e31b531e366289f1d71",
            "dfbf07fcacda4a6ea11249a7fa8e98ce",
            "4c9f916d0f78443a9c180b5dced7e4cc",
            "25aac847e779447b88c81b162bf48974",
            "95ac3bbd47e4445ab162b584114ca2c1",
            "a2c113ddc78c469eaa6bad4009c01770",
            "592bd3ff49b44d77b8414c2edab05be9",
            "796886f682044fce91e51e44d30765a0",
            "8177258ca0e947319dec02aeae5b6381",
            "e97128ea1c744f4b9c6195a0f22d2329",
            "df029d689cec4b02ba1a316ccdf97e3e",
            "a0a054dd486f4bd19c692d851af37d1c",
            "a200be6a31cb4ca98482722d1134dbb9",
            "b8d908d32694456a8e1eaa008623ac63",
            "03f8fa5e157e4cff898d698f257fc0de",
            "f4c27ae844c44b8188a80d54a2d85f06",
            "6a8fb2b3f94d4eb79fbcf25912c9655a",
            "bcbe119185de40eaaf7c684ea67f3d14",
            "c21a16457eda4bb4b5e7ca91d6f3e10e",
            "16f6532f1be5458abfcbea7b24d4bf80",
            "83370e1f6bfe4838980ac4152b0e87ef",
            "b1cb8e66dccd46f594d47dd1c5fb3c96",
            "4e2b497a4af5446b8ad9c79362e270d7",
            "b9f3b733c26f479eb92f3122100c502b",
            "99eb1b39eb344dfeb4cadced9160f96b",
            "fcaa19f7713f4caf9e17fdbdc43217c5",
            "06dbb888be494c7f8fa4c438a115140e",
            "c0dd86dc738e4432b5459f35f7549df1",
            "bc2fc3cbb85544079c07458ad199cee5",
            "8510667c3d6b4830a2953fc2ccaa0866",
            "6a5ce7573dc24e839b4ce45783df8eb9",
            "de7a747a47b1496db0a2bfd31651f2bb",
            "056b9056c77e485b93c0c24b48e1748d",
            "a5b7db3b01ff4ae5a3aa5f21841735b7",
            "1c02991d5569466bb3fc88634870b806",
            "7ce0c9af26234b76b3f5e265445dc1b8",
            "bd9648c2297f47309bdf1e967ff013cf",
            "018ede14e82f45b59fcbd71f8dfb38b7",
            "233a7e0ad28348289f5dd204e74fb8cd",
            "0adf3900c54e4b3eb4ef71fd552232a6",
            "81609093f0ad4348a267f884f2a8dc80",
            "063f7f57bfd44c5daa37d1b7dd39582a",
            "0e4ee443e66145429dc0856d9c317801",
            "f4c44a438cae49ae93327116b87e4bcc",
            "dab3c970a56b4f138a08c7425896d3eb",
            "d8aff408454a4d0f926f963b6f614277",
            "fa157c2d29454a1a85567239f29c7a28",
            "ad4788af94ec4745b43c18028bbec2bd",
            "9867a0e1afb945589c8f46128dee7bb1",
            "3d68cc2250844acea1bb8a9ddecd2310",
            "2bddcf2133c748b8804ae1e26bf8cc04",
            "f86dc72308df4e6ca0b10c55c0865356",
            "e693b089718f40cabaae895ed46c3acb",
            "5bc1371c8d294e69ace3092ca538ba23",
            "66eee02281d84bbd9a1ed1972838b7bd",
            "59237527f49c42dab1cc17591d56c5b0",
            "e492d5fcdac04945abe5c933e2b5325e",
            "855ab17a8955491f954a53183dafe3d2",
            "2348bf1fb3074850ac60c7fff1bf8c23",
            "40132b132a1d46919cfc6726cd18a312",
            "b1b4b18b5eec4fea8238efa368f7b243",
            "000bd9cbd34e4e1d818f47a267ea7241",
            "d8e5a032e9f84d76b12e904ff6d2bb29",
            "3cd4882c7e3a4cf3a44a2dd8c6826345",
            "9e4c862eec254f9890e09b94f63954d3",
            "36f5a26d670d45e5bff6e66947c03d69",
            "a9c1e87100c44873980e6e530cac973b",
            "987cafa6e985497486d896b7bc903781",
            "41599fcd3aa647f5905d9c68f4209204",
            "ca40a10feedb4f0db8601ec483ac28d3",
            "1881f0c1071a4b42b2b85a7d75af4b4d",
            "86a384a1eec248df9d839021bc98183a",
            "f9eb62516a5046098dd8d9ece786f9d4",
            "70dc0e8014de4105b4a7cfc6fcf00fa5",
            "cf34dbf1d2ca410fb52259f559c6a22d",
            "9e4c8f91b16042ccbd48047a43a4b52e",
            "31ddc07c2cbe4977a58d32877b9b46ff",
            "02a3d75d1678401fa6afb7b0dcd89a42",
            "581ce0e5b6c240debf57aa3e1f79f9ca",
            "a526573623274971a5dc8d0b9c5bb231",
            "79a89500b9f94a69a7ae3d8b7f5d61b3",
            "328bcbf1a64949fd856a4b926fd8e943",
            "1e51b834887b4b1a8d59802b65010187",
            "a41cd674999e48ec8b90c2ca89d34e3e",
            "85f125394d464db6bf16db218662974c",
            "454b6f55f4ad4e6c910aa963ad01f02c",
            "dddc14a237fb4b448bc1170dca27e8b5",
            "6a55272a6a6e4bbe88bd8733d7e193c1",
            "3b35e458e8f3474c9f28af44a8991d45",
            "295cbfaded904d2c94761a5a0edbc4d7",
            "c3b1b6dfa24e4a7aa4399da6b0bf369b",
            "8e053d6d71ac4184861a3bf110c11fa2",
            "e7521ffb84804b0c8675055460e14190",
            "c0b4bc16b1874c39bbcc0e1a527504ff",
            "e067c79cd8364328b1496acdeef19028",
            "c548b7c7fa3b4923978b289ab9f60810",
            "8d2d820f5c3d4028a174f3c77e6e68c4",
            "32ab1a984167473290d19fcb13f53ce9",
            "0abdbb7f9fee4af4b8f104818b47688d",
            "0dd4c34db73d476fb623e50bc8fae75d",
            "b3100a3128064e0a8833312b6d8e1bf0",
            "55885dcc834140eeab1d93fe64651d87",
            "c350797e824b40928593008f35310af8",
            "851bac6195024b6681ff3a634fe2bc5d",
            "8c70326deb6648909ef79061b314a540",
            "e279140510294dcfb7359876edf745a9",
            "ce76c8f6605d4581bb5e92658fdb030a",
            "8b83af9dcedb42fc89ce95487490ba0b",
            "4e05ad41957241acb2fef1fa678f3e6e",
            "ff0ebcfa4ebd4aea9fe89aa14d2808ef",
            "3601780dfa1e4d07a728daf016e5b0bc",
            "e7a1bef43219477ba33872d55d1514b0",
            "5f4030a409f745bd94b38faf12da367f",
            "c51dbe1ac99b42b8bc25d965a123e31b",
            "7994e8a4c7c847289e43f6a7111a5041",
            "077b5f4e6e294b588a4a3007a6fdd185",
            "c365b97fbc254ab583d529551fff4f2b",
            "6fb2d0dc3e4d42608012072929c2a612",
            "67c7c2f95be94744b5ca3e93e3390cd7",
            "6de7eef381b343d9985a85179043e671",
            "5819f825276a4e0f9e792d0b5fb0e565",
            "ca91168e72b94b9fa7180f34c373827f",
            "c5e6f739c3c74ad782bee756b6b72c25",
            "9a74a1bc48be423f94ceef5a43226077",
            "e8d76cd7ae864cd1bf14101dddfbaadc",
            "8fce4dfa34664b40a261be0e3e1b9e14",
            "e8b3d49abefb4975a30627068a77d444",
            "2e7abc4343444cd0840db3615282217b",
            "078490d9657b4cca90414a0b5b831928",
            "e6d4eded1dac4ab69ee9cb2f6544f58d"
          ]
        },
        "id": "JoXxvyR-fwlj",
        "outputId": "4809ee33-fc89-4157-c699-d9734d313ab7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d39d045fd3f64722bf4e5b14138527a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e97128ea1c744f4b9c6195a0f22d2329"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83370e1f6bfe4838980ac4152b0e87ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de7a747a47b1496db0a2bfd31651f2bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e4ee443e66145429dc0856d9c317801"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bc1371c8d294e69ace3092ca538ba23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e4c862eec254f9890e09b94f63954d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e4c8f91b16042ccbd48047a43a4b52e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dddc14a237fb4b448bc1170dca27e8b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ab1a984167473290d19fcb13f53ce9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e05ad41957241acb2fef1fa678f3e6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de7eef381b343d9985a85179043e671"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
        "assistant.reset()\n",
        "\n",
        "qa_problem = \"Is there a function called tune_automl?\"\n",
        "chat_results = ragproxyagent.initiate_chat(assistant, message=ragproxyagent.message_generator, problem=qa_problem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9pHmR_ff6Fn",
        "outputId": "1d9f418b-e2ec-4eb1-e6bd-ea5c4fc29553"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to create collection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-27 19:04:50,107 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 3 chunks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorDB returns doc_ids:  [['0d580ff7-7fc1-bf18-cd0c-de037cbd9343', '0ecd7192-3761-7d6f-9151-5ff504ca740b', '9be3ff7b-0243-32ab-5e97-7762580e2663']]\n",
            "Adding content of doc 0d580ff7-7fc1-bf18-cd0c-de037cbd9343 to context.\n",
            "Adding content of doc 0ecd7192-3761-7d6f-9151-5ff504ca740b to context.\n",
            "Adding content of doc 9be3ff7b-0243-32ab-5e97-7762580e2663 to context.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "For code generation, you must obey the following rules:\n",
            "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
            "Rule 2. You must follow the formats below to write your code:\n",
            "```language\n",
            "# your code\n",
            "```\n",
            "\n",
            "User's question is: Is there a function called tune_automl?\n",
            "\n",
            "Context is: [![PyPI version](https://badge.fury.io/py/FLAML.svg)](https://badge.fury.io/py/FLAML)\n",
            "![Conda version](https://img.shields.io/conda/vn/conda-forge/flaml)\n",
            "[![Build](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml/badge.svg)](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml)\n",
            "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/FLAML)](https://pypi.org/project/FLAML/)\n",
            "[![Downloads](https://pepy.tech/badge/flaml)](https://pepy.tech/project/flaml)\n",
            "[![](https://img.shields.io/discord/1025786666260111483?logo=discord&style=flat)](https://discord.gg/Cppx2vSPVP)\n",
            "\n",
            "<!-- [![Join the chat at https://gitter.im/FLAMLer/community](https://badges.gitter.im/FLAMLer/community.svg)](https://gitter.im/FLAMLer/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) -->\n",
            "\n",
            "# A Fast Library for Automated Machine Learning & Tuning\n",
            "\n",
            "<p align=\"center\">\n",
            "    <img src=\"https://github.com/microsoft/FLAML/blob/main/website/static/img/flaml.svg\"  width=200>\n",
            "    <br>\n",
            "</p>\n",
            "\n",
            ":fire: FLAML supports AutoML and Hyperparameter Tuning in [Microsoft Fabric Data Science](https://learn.microsoft.com/en-us/fabric/data-science/automated-machine-learning-fabric). In addition, we've introduced Python 3.11 support, along with a range of new estimators, and comprehensive integration with MLflow—thanks to contributions from the Microsoft Fabric product team.\n",
            "\n",
            ":fire: Heads-up: We have migrated [AutoGen](https://microsoft.github.io/autogen/) into a dedicated [github repository](https://github.com/microsoft/autogen). Alongside this move, we have also launched a dedicated [Discord](https://discord.gg/pAbnFJrkgZ) server and a [website](https://microsoft.github.io/autogen/) for comprehensive documentation.\n",
            "\n",
            ":fire: The automated multi-agent chat framework in [AutoGen](https://microsoft.github.io/autogen/) is in preview from v2.0.0.\n",
            "\n",
            ":fire: FLAML is highlighted in OpenAI's [cookbook](https://github.com/openai/openai-cookbook#related-resources-from-around-the-web).\n",
            "\n",
            ":fire: [autogen](https://microsoft.github.io/autogen/) is released with support for ChatGPT and GPT-4, based on [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673).\n",
            "\n",
            "## What is FLAML\n",
            "\n",
            "FLAML is a lightweight Python library for efficient automation of machine\n",
            "learning and AI operations. It automates workflow based on large language models, machine learning models, etc.\n",
            "and optimizes their performance.\n",
            "\n",
            "- FLAML enables building next-gen GPT-X applications based on multi-agent conversations with minimal effort. It simplifies the orchestration, automation and optimization of a complex GPT-X workflow. It maximizes the performance of GPT-X models and augments their weakness.\n",
            "- For common machine learning tasks like classification and regression, it quickly finds quality models for user-provided data with low computational resources. It is easy to customize or extend. Users can find their desired customizability from a smooth range.\n",
            "- It supports fast and economical automatic tuning (e.g., inference hyperparameters for foundation models, configurations in MLOps/LMOps workflows, pipelines, mathematical/statistical models, algorithms, computing experiments, software configurations), capable of handling large search space with heterogeneous evaluation cost and complex constraints/guidance/early stopping.\n",
            "\n",
            "FLAML is powered by a series of [research studies](https://microsoft.github.io/FLAML/docs/Research/) from Microsoft Research and collaborators such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.\n",
            "\n",
            "FLAML has a .NET implementation in [ML.NET](http://dot.net/ml), an open-source, cross-platform machine learning framework for .NET.\n",
            "\n",
            "## Installation\n",
            "\n",
            "FLAML requires **Python version >= 3.8**. It can be installed from pip:\n",
            "\n",
            "```bash\n",
            "pip install flaml\n",
            "```\n",
            "\n",
            "Minimal dependencies are installed without extra options. You can install extra options based on the feature you need. For example, use the following to install the dependencies needed by the [`autogen`](https://microsoft.github.io/autogen/) package.\n",
            "\n",
            "```bash\n",
            "pip install \"flaml[autogen]\"\n",
            "```\n",
            "\n",
            "Find more options in [Installation](https://microsoft.github.io/FLAML/docs/Installation).\n",
            "Each of the [`notebook examples`](https://github.com/microsoft/FLAML/tree/main/notebook) may require a specific option to be installed.\n",
            "\n",
            "## Quickstart\n",
            "\n",
            "- (New) The [autogen](https://microsoft.github.io/autogen/) package enables the next-gen GPT-X applications with a generic multi-agent conversation framework.\n",
            "  It offers customizable and conversable agents which integrate LLMs, tools and human.\n",
            "  By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code. For example,\n",
            "\n",
            "```python\n",
            "from flaml import autogen\n",
            "\n",
            "assistant = autogen.AssistantAgent(\"assistant\")\n",
            "user_proxy = autogen.UserProxyAgent(\"user_proxy\")\n",
            "user_proxy.initiate_chat(\n",
            "    assistant,\n",
            "    message=\"Show me the YTD gain of 10 largest technology companies as of today.\",\n",
            ")\n",
            "# This initiates an automated chat between the two agents to solve the task\n",
            "```\n",
            "\n",
            "Autogen also helps maximize the utility out of the expensive LLMs such as ChatGPT and GPT-4. It offers a drop-in replacement of `openai.Completion` or `openai.ChatCompletion` with powerful functionalites like tuning, caching, templating, filtering. For example, you can optimize generations by LLM with your own tuning data, success metrics and budgets.\n",
            "\n",
            "```python\n",
            "# perform tuning\n",
            "config, analysis = autogen.Completion.tune(\n",
            "    data=tune_data,\n",
            "    metric=\"success\",\n",
            "    mode=\"max\",\n",
            "    eval_func=eval_func,\n",
            "    inference_budget=0.05,\n",
            "    optimization_budget=3,\n",
            "    num_samples=-1,\n",
            ")\n",
            "# perform inference for a test instance\n",
            "response = autogen.Completion.create(context=test_instance, **config)\n",
            "```\n",
            "\n",
            "- With three lines of code, you can start using this economical and fast\n",
            "  AutoML engine as a [scikit-learn style estimator](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML).\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "\n",
            "automl = AutoML()\n",
            "automl.fit(X_train, y_train, task=\"classification\")\n",
            "```\n",
            "\n",
            "- You can restrict the learners and use FLAML as a fast hyperparameter tuning\n",
            "  tool for XGBoost, LightGBM, Random Forest etc. or a [customized learner](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#estimator-and-search-space).\n",
            "\n",
            "```python\n",
            "automl.fit(X_train, y_train, task=\"classification\", estimator_list=[\"lgbm\"])\n",
            "```\n",
            "\n",
            "- You can also run generic hyperparameter tuning for a [custom function](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function).\n",
            "\n",
            "```python\n",
            "from flaml import tune\n",
            "tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)\n",
            "```\n",
            "\n",
            "- [Zero-shot AutoML](https://microsoft.github.io/FLAML/docs/Use-Cases/Zero-Shot-AutoML) allows using the existing training API from lightgbm, xgboost etc. while getting the benefit of AutoML in choosing high-performance hyperparameter configurations per task.\n",
            "\n",
            "```python\n",
            "from flaml.default import LGBMRegressor\n",
            "\n",
            "# Use LGBMRegressor in the same way as you use lightgbm.LGBMRegressor.\n",
            "estimator = LGBMRegressor()\n",
            "# The hyperparameters are automatically set according to the training data.\n",
            "estimator.fit(X_train, y_train)\n",
            "```\n",
            "\n",
            "## Documentation\n",
            "\n",
            "You can find a detailed documentation about FLAML [here](https://microsoft.github.io/FLAML/).\n",
            "\n",
            "In addition, you can find:\n",
            "\n",
            "- [Research](https://microsoft.github.io/FLAML/docs/Research) and [blogposts](https://microsoft.github.io/FLAML/blog) around FLAML.\n",
            "\n",
            "- [Discord](https://discord.gg/Cppx2vSPVP).\n",
            "\n",
            "- [Contributing guide](https://microsoft.github.io/FLAML/docs/Contribute).\n",
            "\n",
            "- ML.NET documentation and tutorials for [Model Builder](https://learn.microsoft.com/dotnet/machine-learning/tutorials/predict-prices-with-model-builder), [ML.NET CLI](https://learn.microsoft.com/dotnet/machine-learning/tutorials/sentiment-analysis-cli), and [AutoML API](https://learn.microsoft.com/dotnet/machine-learning/how-to-guides/how-to-use-the-automl-api).\n",
            "\n",
            "## Contributing\n",
            "\n",
            "This project welcomes contributions and suggestions. Most contributions require you to agree to a\n",
            "Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n",
            "the rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\n",
            "# Research\n",
            "\n",
            "For technical details, please check our research publications.\n",
            "\n",
            "- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021flaml,\n",
            "    title={FLAML: A Fast and Lightweight AutoML Library},\n",
            "    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},\n",
            "    year={2021},\n",
            "    booktitle={MLSys},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021cfo,\n",
            "    title={Frugal Optimization for Cost-related Hyperparameters},\n",
            "    author={Qingyun Wu and Chi Wang and Silu Huang},\n",
            "    year={2021},\n",
            "    booktitle={AAAI},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021blendsearch,\n",
            "    title={Economical Hyperparameter Optimization With Blended Search Strategy},\n",
            "    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},\n",
            "    year={2021},\n",
            "    booktitle={ICLR},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{liuwang2021hpolm,\n",
            "    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},\n",
            "    author={Susan Xueqing Liu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ACL},\n",
            "}\n",
            "```\n",
            "\n",
            "- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021chacha,\n",
            "    title={ChaCha for Online AutoML},\n",
            "    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},\n",
            "    year={2021},\n",
            "    booktitle={ICML},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wuwang2021fairautoml,\n",
            "    title={Fair AutoML},\n",
            "    author={Qingyun Wu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ArXiv preprint arXiv:2111.06495},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{kayaliwang2022default,\n",
            "    title={Mining Robust Default Configurations for Resource-constrained AutoML},\n",
            "    author={Moe Kayali and Chi Wang},\n",
            "    year={2022},\n",
            "    booktitle={ArXiv preprint arXiv:2202.09927},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{zhang2023targeted,\n",
            "    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},\n",
            "    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},\n",
            "    booktitle={International Conference on Learning Representations},\n",
            "    year={2023},\n",
            "    url={https://openreview.net/forum?id=0Ij9_q567Ma},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2023EcoOptiGen,\n",
            "    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},\n",
            "    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2303.04673},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2023empirical,\n",
            "    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},\n",
            "    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2306.01337},\n",
            "}\n",
            "```\n",
            "If you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.\n",
            "\n",
            "When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n",
            "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n",
            "provided by the bot. You will only need to do this once across all repos using our CLA.\n",
            "\n",
            "This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n",
            "For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n",
            "contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
            "\n",
            "## Contributors Wall\n",
            "\n",
            "<a href=\"https://github.com/microsoft/flaml/graphs/contributors\">\n",
            "  <img src=\"https://contrib.rocks/image?repo=microsoft/flaml&max=204\" />\n",
            "</a>\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "Based on the context provided, which is detailed information about FLAML (Fast Library for Automated Machine Learning & Tuning), there isn't a specific mention of a function called `tune_automl` directly within the text. FLAML is an automated machine learning and hyperparameter tuning library that offers different functionalities related to AutoML, including but not limited to hyperparameter optimization, custom function tuning, and integration with large language models via the `autogen` package.\n",
            "\n",
            "When it comes to tuning and AutoML capabilities within FLAML, the documentation and examples highlighted focus on functionalities such as:\n",
            "\n",
            "- Utilizing the `AutoML` class for automated machine learning tasks.\n",
            "- Conducting generic hyperparameter tuning using the `tune.run` function.\n",
            "- Specialized tuning capabilities through the `autogen` package for optimizing interactions with large language models.\n",
            "\n",
            "Given the specific inquiry about `tune_automl`, it might refer to the concept of tuning AutoML processes, which is a core functionality of FLAML but might not directly correspond to a function named `tune_automl`. Instead, FLAML provides a broad suite of tools and functions for various aspects of AutoML, including but not limited to the efficient search for optimal hyperparameters (via `AutoML` class and `tune` module), integration with machine learning workflows, and customization of the machine learning process.\n",
            "\n",
            "For direct interaction with FLAML for tuning and AutoML, you would typically start with something like:\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "automl = AutoML()\n",
            "automl.fit(X_train, y_train, task=\"classification\")\n",
            "```\n",
            "\n",
            "Or for hyperparameter optimization:\n",
            "\n",
            "```python\n",
            "from flaml import tune\n",
            "tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)\n",
            "```\n",
            "\n",
            "If your interest is specifically around a function called `tune_automl`, it would be useful to review the latest FLAML documentation or check the source code directly for any recent additions or changes that might include this functionality.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "UPDATE CONTEXT\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Updating context and resetting conversation.\n",
            "VectorDB returns doc_ids:  [['0d580ff7-7fc1-bf18-cd0c-de037cbd9343', '0ecd7192-3761-7d6f-9151-5ff504ca740b', '9be3ff7b-0243-32ab-5e97-7762580e2663']]\n",
            "No more context, will terminate.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
        "assistant.reset()\n",
        "\n",
        "qa_problem = \"Who is the author of FLAML?\"\n",
        "chat_results = ragproxyagent.initiate_chat(assistant, message=ragproxyagent.message_generator, problem=qa_problem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCuhglxhgcWg",
        "outputId": "40539735-a501-4afc-fefb-432001c61d37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorDB returns doc_ids:  [['0d580ff7-7fc1-bf18-cd0c-de037cbd9343', '0ecd7192-3761-7d6f-9151-5ff504ca740b', '9be3ff7b-0243-32ab-5e97-7762580e2663']]\n",
            "Adding content of doc 0d580ff7-7fc1-bf18-cd0c-de037cbd9343 to context.\n",
            "Adding content of doc 0ecd7192-3761-7d6f-9151-5ff504ca740b to context.\n",
            "Adding content of doc 9be3ff7b-0243-32ab-5e97-7762580e2663 to context.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "For code generation, you must obey the following rules:\n",
            "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
            "Rule 2. You must follow the formats below to write your code:\n",
            "```language\n",
            "# your code\n",
            "```\n",
            "\n",
            "User's question is: Who is the author of FLAML?\n",
            "\n",
            "Context is: [![PyPI version](https://badge.fury.io/py/FLAML.svg)](https://badge.fury.io/py/FLAML)\n",
            "![Conda version](https://img.shields.io/conda/vn/conda-forge/flaml)\n",
            "[![Build](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml/badge.svg)](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml)\n",
            "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/FLAML)](https://pypi.org/project/FLAML/)\n",
            "[![Downloads](https://pepy.tech/badge/flaml)](https://pepy.tech/project/flaml)\n",
            "[![](https://img.shields.io/discord/1025786666260111483?logo=discord&style=flat)](https://discord.gg/Cppx2vSPVP)\n",
            "\n",
            "<!-- [![Join the chat at https://gitter.im/FLAMLer/community](https://badges.gitter.im/FLAMLer/community.svg)](https://gitter.im/FLAMLer/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) -->\n",
            "\n",
            "# A Fast Library for Automated Machine Learning & Tuning\n",
            "\n",
            "<p align=\"center\">\n",
            "    <img src=\"https://github.com/microsoft/FLAML/blob/main/website/static/img/flaml.svg\"  width=200>\n",
            "    <br>\n",
            "</p>\n",
            "\n",
            ":fire: FLAML supports AutoML and Hyperparameter Tuning in [Microsoft Fabric Data Science](https://learn.microsoft.com/en-us/fabric/data-science/automated-machine-learning-fabric). In addition, we've introduced Python 3.11 support, along with a range of new estimators, and comprehensive integration with MLflow—thanks to contributions from the Microsoft Fabric product team.\n",
            "\n",
            ":fire: Heads-up: We have migrated [AutoGen](https://microsoft.github.io/autogen/) into a dedicated [github repository](https://github.com/microsoft/autogen). Alongside this move, we have also launched a dedicated [Discord](https://discord.gg/pAbnFJrkgZ) server and a [website](https://microsoft.github.io/autogen/) for comprehensive documentation.\n",
            "\n",
            ":fire: The automated multi-agent chat framework in [AutoGen](https://microsoft.github.io/autogen/) is in preview from v2.0.0.\n",
            "\n",
            ":fire: FLAML is highlighted in OpenAI's [cookbook](https://github.com/openai/openai-cookbook#related-resources-from-around-the-web).\n",
            "\n",
            ":fire: [autogen](https://microsoft.github.io/autogen/) is released with support for ChatGPT and GPT-4, based on [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673).\n",
            "\n",
            "## What is FLAML\n",
            "\n",
            "FLAML is a lightweight Python library for efficient automation of machine\n",
            "learning and AI operations. It automates workflow based on large language models, machine learning models, etc.\n",
            "and optimizes their performance.\n",
            "\n",
            "- FLAML enables building next-gen GPT-X applications based on multi-agent conversations with minimal effort. It simplifies the orchestration, automation and optimization of a complex GPT-X workflow. It maximizes the performance of GPT-X models and augments their weakness.\n",
            "- For common machine learning tasks like classification and regression, it quickly finds quality models for user-provided data with low computational resources. It is easy to customize or extend. Users can find their desired customizability from a smooth range.\n",
            "- It supports fast and economical automatic tuning (e.g., inference hyperparameters for foundation models, configurations in MLOps/LMOps workflows, pipelines, mathematical/statistical models, algorithms, computing experiments, software configurations), capable of handling large search space with heterogeneous evaluation cost and complex constraints/guidance/early stopping.\n",
            "\n",
            "FLAML is powered by a series of [research studies](https://microsoft.github.io/FLAML/docs/Research/) from Microsoft Research and collaborators such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.\n",
            "\n",
            "FLAML has a .NET implementation in [ML.NET](http://dot.net/ml), an open-source, cross-platform machine learning framework for .NET.\n",
            "\n",
            "## Installation\n",
            "\n",
            "FLAML requires **Python version >= 3.8**. It can be installed from pip:\n",
            "\n",
            "```bash\n",
            "pip install flaml\n",
            "```\n",
            "\n",
            "Minimal dependencies are installed without extra options. You can install extra options based on the feature you need. For example, use the following to install the dependencies needed by the [`autogen`](https://microsoft.github.io/autogen/) package.\n",
            "\n",
            "```bash\n",
            "pip install \"flaml[autogen]\"\n",
            "```\n",
            "\n",
            "Find more options in [Installation](https://microsoft.github.io/FLAML/docs/Installation).\n",
            "Each of the [`notebook examples`](https://github.com/microsoft/FLAML/tree/main/notebook) may require a specific option to be installed.\n",
            "\n",
            "## Quickstart\n",
            "\n",
            "- (New) The [autogen](https://microsoft.github.io/autogen/) package enables the next-gen GPT-X applications with a generic multi-agent conversation framework.\n",
            "  It offers customizable and conversable agents which integrate LLMs, tools and human.\n",
            "  By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code. For example,\n",
            "\n",
            "```python\n",
            "from flaml import autogen\n",
            "\n",
            "assistant = autogen.AssistantAgent(\"assistant\")\n",
            "user_proxy = autogen.UserProxyAgent(\"user_proxy\")\n",
            "user_proxy.initiate_chat(\n",
            "    assistant,\n",
            "    message=\"Show me the YTD gain of 10 largest technology companies as of today.\",\n",
            ")\n",
            "# This initiates an automated chat between the two agents to solve the task\n",
            "```\n",
            "\n",
            "Autogen also helps maximize the utility out of the expensive LLMs such as ChatGPT and GPT-4. It offers a drop-in replacement of `openai.Completion` or `openai.ChatCompletion` with powerful functionalites like tuning, caching, templating, filtering. For example, you can optimize generations by LLM with your own tuning data, success metrics and budgets.\n",
            "\n",
            "```python\n",
            "# perform tuning\n",
            "config, analysis = autogen.Completion.tune(\n",
            "    data=tune_data,\n",
            "    metric=\"success\",\n",
            "    mode=\"max\",\n",
            "    eval_func=eval_func,\n",
            "    inference_budget=0.05,\n",
            "    optimization_budget=3,\n",
            "    num_samples=-1,\n",
            ")\n",
            "# perform inference for a test instance\n",
            "response = autogen.Completion.create(context=test_instance, **config)\n",
            "```\n",
            "\n",
            "- With three lines of code, you can start using this economical and fast\n",
            "  AutoML engine as a [scikit-learn style estimator](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML).\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "\n",
            "automl = AutoML()\n",
            "automl.fit(X_train, y_train, task=\"classification\")\n",
            "```\n",
            "\n",
            "- You can restrict the learners and use FLAML as a fast hyperparameter tuning\n",
            "  tool for XGBoost, LightGBM, Random Forest etc. or a [customized learner](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#estimator-and-search-space).\n",
            "\n",
            "```python\n",
            "automl.fit(X_train, y_train, task=\"classification\", estimator_list=[\"lgbm\"])\n",
            "```\n",
            "\n",
            "- You can also run generic hyperparameter tuning for a [custom function](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function).\n",
            "\n",
            "```python\n",
            "from flaml import tune\n",
            "tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)\n",
            "```\n",
            "\n",
            "- [Zero-shot AutoML](https://microsoft.github.io/FLAML/docs/Use-Cases/Zero-Shot-AutoML) allows using the existing training API from lightgbm, xgboost etc. while getting the benefit of AutoML in choosing high-performance hyperparameter configurations per task.\n",
            "\n",
            "```python\n",
            "from flaml.default import LGBMRegressor\n",
            "\n",
            "# Use LGBMRegressor in the same way as you use lightgbm.LGBMRegressor.\n",
            "estimator = LGBMRegressor()\n",
            "# The hyperparameters are automatically set according to the training data.\n",
            "estimator.fit(X_train, y_train)\n",
            "```\n",
            "\n",
            "## Documentation\n",
            "\n",
            "You can find a detailed documentation about FLAML [here](https://microsoft.github.io/FLAML/).\n",
            "\n",
            "In addition, you can find:\n",
            "\n",
            "- [Research](https://microsoft.github.io/FLAML/docs/Research) and [blogposts](https://microsoft.github.io/FLAML/blog) around FLAML.\n",
            "\n",
            "- [Discord](https://discord.gg/Cppx2vSPVP).\n",
            "\n",
            "- [Contributing guide](https://microsoft.github.io/FLAML/docs/Contribute).\n",
            "\n",
            "- ML.NET documentation and tutorials for [Model Builder](https://learn.microsoft.com/dotnet/machine-learning/tutorials/predict-prices-with-model-builder), [ML.NET CLI](https://learn.microsoft.com/dotnet/machine-learning/tutorials/sentiment-analysis-cli), and [AutoML API](https://learn.microsoft.com/dotnet/machine-learning/how-to-guides/how-to-use-the-automl-api).\n",
            "\n",
            "## Contributing\n",
            "\n",
            "This project welcomes contributions and suggestions. Most contributions require you to agree to a\n",
            "Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n",
            "the rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\n",
            "# Research\n",
            "\n",
            "For technical details, please check our research publications.\n",
            "\n",
            "- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021flaml,\n",
            "    title={FLAML: A Fast and Lightweight AutoML Library},\n",
            "    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},\n",
            "    year={2021},\n",
            "    booktitle={MLSys},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021cfo,\n",
            "    title={Frugal Optimization for Cost-related Hyperparameters},\n",
            "    author={Qingyun Wu and Chi Wang and Silu Huang},\n",
            "    year={2021},\n",
            "    booktitle={AAAI},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021blendsearch,\n",
            "    title={Economical Hyperparameter Optimization With Blended Search Strategy},\n",
            "    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},\n",
            "    year={2021},\n",
            "    booktitle={ICLR},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{liuwang2021hpolm,\n",
            "    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},\n",
            "    author={Susan Xueqing Liu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ACL},\n",
            "}\n",
            "```\n",
            "\n",
            "- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021chacha,\n",
            "    title={ChaCha for Online AutoML},\n",
            "    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},\n",
            "    year={2021},\n",
            "    booktitle={ICML},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wuwang2021fairautoml,\n",
            "    title={Fair AutoML},\n",
            "    author={Qingyun Wu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ArXiv preprint arXiv:2111.06495},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{kayaliwang2022default,\n",
            "    title={Mining Robust Default Configurations for Resource-constrained AutoML},\n",
            "    author={Moe Kayali and Chi Wang},\n",
            "    year={2022},\n",
            "    booktitle={ArXiv preprint arXiv:2202.09927},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{zhang2023targeted,\n",
            "    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},\n",
            "    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},\n",
            "    booktitle={International Conference on Learning Representations},\n",
            "    year={2023},\n",
            "    url={https://openreview.net/forum?id=0Ij9_q567Ma},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2023EcoOptiGen,\n",
            "    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},\n",
            "    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2303.04673},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2023empirical,\n",
            "    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},\n",
            "    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2306.01337},\n",
            "}\n",
            "```\n",
            "If you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.\n",
            "\n",
            "When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n",
            "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n",
            "provided by the bot. You will only need to do this once across all repos using our CLA.\n",
            "\n",
            "This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n",
            "For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n",
            "contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
            "\n",
            "## Contributors Wall\n",
            "\n",
            "<a href=\"https://github.com/microsoft/flaml/graphs/contributors\">\n",
            "  <img src=\"https://contrib.rocks/image?repo=microsoft/flaml&max=204\" />\n",
            "</a>\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "The authors of FLAML, as mentioned in the provided research publications, include Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu, Silu Huang, Amin Saied, Susan Xueqing Liu, John Langford, Paul Mineiro, Marco Rossi, and collaborators from institutions such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(chat_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHXwoRsxhCIE",
        "outputId": "c9678478-138b-42be-e46e-797b79a8c923"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "autogen.agentchat.chat.ChatResult"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_results.chat_history[-1]['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "T77fI_k2hGCI",
        "outputId": "9dacefbe-7d4e-46a8-907a-b6e14e5c79d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The authors of FLAML, as mentioned in the provided research publications, include Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu, Silu Huang, Amin Saied, Susan Xueqing Liu, John Langford, Paul Mineiro, Marco Rossi, and collaborators from institutions such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
        "assistant.reset()\n",
        "\n",
        "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
        "ragproxyagent.human_input_mode = \"ALWAYS\"\n",
        "code_problem = \"how to build a time series forecasting model for stock price using FLAML?\"\n",
        "chat_result = ragproxyagent.initiate_chat(assistant, message=ragproxyagent.message_generator, problem=code_problem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn5i0Jj9hdw9",
        "outputId": "b9a1892b-0e86-4f9b-8b24-db9560bef7a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VectorDB returns doc_ids:  [['0d580ff7-7fc1-bf18-cd0c-de037cbd9343', '0ecd7192-3761-7d6f-9151-5ff504ca740b', '9be3ff7b-0243-32ab-5e97-7762580e2663']]\n",
            "Adding content of doc 0d580ff7-7fc1-bf18-cd0c-de037cbd9343 to context.\n",
            "Adding content of doc 0ecd7192-3761-7d6f-9151-5ff504ca740b to context.\n",
            "Adding content of doc 9be3ff7b-0243-32ab-5e97-7762580e2663 to context.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "For code generation, you must obey the following rules:\n",
            "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
            "Rule 2. You must follow the formats below to write your code:\n",
            "```language\n",
            "# your code\n",
            "```\n",
            "\n",
            "User's question is: how to build a time series forecasting model for stock price using FLAML?\n",
            "\n",
            "Context is: [![PyPI version](https://badge.fury.io/py/FLAML.svg)](https://badge.fury.io/py/FLAML)\n",
            "![Conda version](https://img.shields.io/conda/vn/conda-forge/flaml)\n",
            "[![Build](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml/badge.svg)](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml)\n",
            "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/FLAML)](https://pypi.org/project/FLAML/)\n",
            "[![Downloads](https://pepy.tech/badge/flaml)](https://pepy.tech/project/flaml)\n",
            "[![](https://img.shields.io/discord/1025786666260111483?logo=discord&style=flat)](https://discord.gg/Cppx2vSPVP)\n",
            "\n",
            "<!-- [![Join the chat at https://gitter.im/FLAMLer/community](https://badges.gitter.im/FLAMLer/community.svg)](https://gitter.im/FLAMLer/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) -->\n",
            "\n",
            "# A Fast Library for Automated Machine Learning & Tuning\n",
            "\n",
            "<p align=\"center\">\n",
            "    <img src=\"https://github.com/microsoft/FLAML/blob/main/website/static/img/flaml.svg\"  width=200>\n",
            "    <br>\n",
            "</p>\n",
            "\n",
            ":fire: FLAML supports AutoML and Hyperparameter Tuning in [Microsoft Fabric Data Science](https://learn.microsoft.com/en-us/fabric/data-science/automated-machine-learning-fabric). In addition, we've introduced Python 3.11 support, along with a range of new estimators, and comprehensive integration with MLflow—thanks to contributions from the Microsoft Fabric product team.\n",
            "\n",
            ":fire: Heads-up: We have migrated [AutoGen](https://microsoft.github.io/autogen/) into a dedicated [github repository](https://github.com/microsoft/autogen). Alongside this move, we have also launched a dedicated [Discord](https://discord.gg/pAbnFJrkgZ) server and a [website](https://microsoft.github.io/autogen/) for comprehensive documentation.\n",
            "\n",
            ":fire: The automated multi-agent chat framework in [AutoGen](https://microsoft.github.io/autogen/) is in preview from v2.0.0.\n",
            "\n",
            ":fire: FLAML is highlighted in OpenAI's [cookbook](https://github.com/openai/openai-cookbook#related-resources-from-around-the-web).\n",
            "\n",
            ":fire: [autogen](https://microsoft.github.io/autogen/) is released with support for ChatGPT and GPT-4, based on [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673).\n",
            "\n",
            "## What is FLAML\n",
            "\n",
            "FLAML is a lightweight Python library for efficient automation of machine\n",
            "learning and AI operations. It automates workflow based on large language models, machine learning models, etc.\n",
            "and optimizes their performance.\n",
            "\n",
            "- FLAML enables building next-gen GPT-X applications based on multi-agent conversations with minimal effort. It simplifies the orchestration, automation and optimization of a complex GPT-X workflow. It maximizes the performance of GPT-X models and augments their weakness.\n",
            "- For common machine learning tasks like classification and regression, it quickly finds quality models for user-provided data with low computational resources. It is easy to customize or extend. Users can find their desired customizability from a smooth range.\n",
            "- It supports fast and economical automatic tuning (e.g., inference hyperparameters for foundation models, configurations in MLOps/LMOps workflows, pipelines, mathematical/statistical models, algorithms, computing experiments, software configurations), capable of handling large search space with heterogeneous evaluation cost and complex constraints/guidance/early stopping.\n",
            "\n",
            "FLAML is powered by a series of [research studies](https://microsoft.github.io/FLAML/docs/Research/) from Microsoft Research and collaborators such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.\n",
            "\n",
            "FLAML has a .NET implementation in [ML.NET](http://dot.net/ml), an open-source, cross-platform machine learning framework for .NET.\n",
            "\n",
            "## Installation\n",
            "\n",
            "FLAML requires **Python version >= 3.8**. It can be installed from pip:\n",
            "\n",
            "```bash\n",
            "pip install flaml\n",
            "```\n",
            "\n",
            "Minimal dependencies are installed without extra options. You can install extra options based on the feature you need. For example, use the following to install the dependencies needed by the [`autogen`](https://microsoft.github.io/autogen/) package.\n",
            "\n",
            "```bash\n",
            "pip install \"flaml[autogen]\"\n",
            "```\n",
            "\n",
            "Find more options in [Installation](https://microsoft.github.io/FLAML/docs/Installation).\n",
            "Each of the [`notebook examples`](https://github.com/microsoft/FLAML/tree/main/notebook) may require a specific option to be installed.\n",
            "\n",
            "## Quickstart\n",
            "\n",
            "- (New) The [autogen](https://microsoft.github.io/autogen/) package enables the next-gen GPT-X applications with a generic multi-agent conversation framework.\n",
            "  It offers customizable and conversable agents which integrate LLMs, tools and human.\n",
            "  By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code. For example,\n",
            "\n",
            "```python\n",
            "from flaml import autogen\n",
            "\n",
            "assistant = autogen.AssistantAgent(\"assistant\")\n",
            "user_proxy = autogen.UserProxyAgent(\"user_proxy\")\n",
            "user_proxy.initiate_chat(\n",
            "    assistant,\n",
            "    message=\"Show me the YTD gain of 10 largest technology companies as of today.\",\n",
            ")\n",
            "# This initiates an automated chat between the two agents to solve the task\n",
            "```\n",
            "\n",
            "Autogen also helps maximize the utility out of the expensive LLMs such as ChatGPT and GPT-4. It offers a drop-in replacement of `openai.Completion` or `openai.ChatCompletion` with powerful functionalites like tuning, caching, templating, filtering. For example, you can optimize generations by LLM with your own tuning data, success metrics and budgets.\n",
            "\n",
            "```python\n",
            "# perform tuning\n",
            "config, analysis = autogen.Completion.tune(\n",
            "    data=tune_data,\n",
            "    metric=\"success\",\n",
            "    mode=\"max\",\n",
            "    eval_func=eval_func,\n",
            "    inference_budget=0.05,\n",
            "    optimization_budget=3,\n",
            "    num_samples=-1,\n",
            ")\n",
            "# perform inference for a test instance\n",
            "response = autogen.Completion.create(context=test_instance, **config)\n",
            "```\n",
            "\n",
            "- With three lines of code, you can start using this economical and fast\n",
            "  AutoML engine as a [scikit-learn style estimator](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML).\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "\n",
            "automl = AutoML()\n",
            "automl.fit(X_train, y_train, task=\"classification\")\n",
            "```\n",
            "\n",
            "- You can restrict the learners and use FLAML as a fast hyperparameter tuning\n",
            "  tool for XGBoost, LightGBM, Random Forest etc. or a [customized learner](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#estimator-and-search-space).\n",
            "\n",
            "```python\n",
            "automl.fit(X_train, y_train, task=\"classification\", estimator_list=[\"lgbm\"])\n",
            "```\n",
            "\n",
            "- You can also run generic hyperparameter tuning for a [custom function](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function).\n",
            "\n",
            "```python\n",
            "from flaml import tune\n",
            "tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)\n",
            "```\n",
            "\n",
            "- [Zero-shot AutoML](https://microsoft.github.io/FLAML/docs/Use-Cases/Zero-Shot-AutoML) allows using the existing training API from lightgbm, xgboost etc. while getting the benefit of AutoML in choosing high-performance hyperparameter configurations per task.\n",
            "\n",
            "```python\n",
            "from flaml.default import LGBMRegressor\n",
            "\n",
            "# Use LGBMRegressor in the same way as you use lightgbm.LGBMRegressor.\n",
            "estimator = LGBMRegressor()\n",
            "# The hyperparameters are automatically set according to the training data.\n",
            "estimator.fit(X_train, y_train)\n",
            "```\n",
            "\n",
            "## Documentation\n",
            "\n",
            "You can find a detailed documentation about FLAML [here](https://microsoft.github.io/FLAML/).\n",
            "\n",
            "In addition, you can find:\n",
            "\n",
            "- [Research](https://microsoft.github.io/FLAML/docs/Research) and [blogposts](https://microsoft.github.io/FLAML/blog) around FLAML.\n",
            "\n",
            "- [Discord](https://discord.gg/Cppx2vSPVP).\n",
            "\n",
            "- [Contributing guide](https://microsoft.github.io/FLAML/docs/Contribute).\n",
            "\n",
            "- ML.NET documentation and tutorials for [Model Builder](https://learn.microsoft.com/dotnet/machine-learning/tutorials/predict-prices-with-model-builder), [ML.NET CLI](https://learn.microsoft.com/dotnet/machine-learning/tutorials/sentiment-analysis-cli), and [AutoML API](https://learn.microsoft.com/dotnet/machine-learning/how-to-guides/how-to-use-the-automl-api).\n",
            "\n",
            "## Contributing\n",
            "\n",
            "This project welcomes contributions and suggestions. Most contributions require you to agree to a\n",
            "Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n",
            "the rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\n",
            "# Research\n",
            "\n",
            "For technical details, please check our research publications.\n",
            "\n",
            "- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021flaml,\n",
            "    title={FLAML: A Fast and Lightweight AutoML Library},\n",
            "    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},\n",
            "    year={2021},\n",
            "    booktitle={MLSys},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021cfo,\n",
            "    title={Frugal Optimization for Cost-related Hyperparameters},\n",
            "    author={Qingyun Wu and Chi Wang and Silu Huang},\n",
            "    year={2021},\n",
            "    booktitle={AAAI},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021blendsearch,\n",
            "    title={Economical Hyperparameter Optimization With Blended Search Strategy},\n",
            "    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},\n",
            "    year={2021},\n",
            "    booktitle={ICLR},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{liuwang2021hpolm,\n",
            "    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},\n",
            "    author={Susan Xueqing Liu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ACL},\n",
            "}\n",
            "```\n",
            "\n",
            "- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021chacha,\n",
            "    title={ChaCha for Online AutoML},\n",
            "    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},\n",
            "    year={2021},\n",
            "    booktitle={ICML},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wuwang2021fairautoml,\n",
            "    title={Fair AutoML},\n",
            "    author={Qingyun Wu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ArXiv preprint arXiv:2111.06495},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{kayaliwang2022default,\n",
            "    title={Mining Robust Default Configurations for Resource-constrained AutoML},\n",
            "    author={Moe Kayali and Chi Wang},\n",
            "    year={2022},\n",
            "    booktitle={ArXiv preprint arXiv:2202.09927},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{zhang2023targeted,\n",
            "    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},\n",
            "    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},\n",
            "    booktitle={International Conference on Learning Representations},\n",
            "    year={2023},\n",
            "    url={https://openreview.net/forum?id=0Ij9_q567Ma},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2023EcoOptiGen,\n",
            "    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},\n",
            "    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2303.04673},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2023empirical,\n",
            "    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},\n",
            "    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2306.01337},\n",
            "}\n",
            "```\n",
            "If you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.\n",
            "\n",
            "When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n",
            "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n",
            "provided by the bot. You will only need to do this once across all repos using our CLA.\n",
            "\n",
            "This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n",
            "For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n",
            "contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
            "\n",
            "## Contributors Wall\n",
            "\n",
            "<a href=\"https://github.com/microsoft/flaml/graphs/contributors\">\n",
            "  <img src=\"https://contrib.rocks/image?repo=microsoft/flaml&max=204\" />\n",
            "</a>\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "from sklearn.model_selection import train_test_split\n",
            "import pandas as pd\n",
            "\n",
            "# Assuming `df` is your DataFrame containing the stock price data with a 'Date' column and a 'Close' column\n",
            "# First, let's convert 'Date' to datetime type if it's not already\n",
            "df['Date'] = pd.to_datetime(df['Date'])\n",
            "\n",
            "# Setting 'Date' as the index\n",
            "df.set_index('Date', inplace=True)\n",
            "\n",
            "# Let's say 'Close' is the column we want to predict\n",
            "# For a time series forecasting model, we should split the data based on time\n",
            "split_date = '2023-01-01'  # This is an example split date, adjust based on your dataset\n",
            "\n",
            "# Splitting the data into train and test sets\n",
            "train = df.loc[df.index < split_date]\n",
            "test = df.loc[df.index >= split_date]\n",
            "\n",
            "# For time series forecasting, it's common to use previous values as features\n",
            "# Here, you can generate features based on your requirement, like lags of 'Close'\n",
            "# For simplicity, we'll use only 'Close' as our feature to train the model\n",
            "\n",
            "X_train, y_train = train[['Close']].values[:-1], train['Close'].values[1:]\n",
            "X_test, y_test = test[['Close']].values[:-1], test['Close'].values[1:]\n",
            "\n",
            "# Initialize the AutoML instance\n",
            "automl = AutoML()\n",
            "\n",
            "# Specify the task as 'forecast' and set the time_budget. Adjust based on your needs.\n",
            "automl_settings = {\n",
            "    \"time_budget\": 120,  # Time budget in seconds\n",
            "    \"metric\": 'mae',  # Metric to optimize for. Adjust accordingly (e.g., 'mse' for Mean Squared Error)\n",
            "    \"task\": 'forecast',  # Specify the task type\n",
            "    \"log_file_name\": \"stock_forecast.log\",  # Log file\n",
            "}\n",
            "\n",
            "# Start the AutoML run\n",
            "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
            "\n",
            "# Predicting on the test set\n",
            "y_pred = automl.predict(X_test)\n",
            "\n",
            "# You can evaluate the predictions using your preferred metrics, such as MAE, MSE, etc.\n",
            "```\n",
            "\n",
            "This script demonstrates how to use FLAML for time series forecasting with a focus on stock price prediction. Note that for more complex time series patterns and feature engineering, you may want to include additional steps for generating more informative features, handling seasonality and trends, and potentially transforming your target variable (e.g., using differencing to make the series stationary).\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as ragproxyagent. Provide feedback to assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_content = chat_results.chat_history[-1]['content']\n",
        "import markdown\n",
        "from markdownify import markdownify\n",
        "# Convert to Markdown\n",
        "markdown_content = markdown.markdown(last_content)\n",
        "\n",
        "markdown_content = markdownify(markdown_content)\n",
        "\n",
        "# Print the Markdown content\n",
        "print(markdown_content)\n",
        "\n",
        "print(markdown_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjMgKIrHh2-v",
        "outputId": "d31c3018-30d1-4984-cda1-90ef8a8b3e10"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "from sklearn.model\\_selection import train\\_test\\_split\n",
            "import pandas as pd\n",
            "\n",
            "Assuming `df` is your DataFrame containing the stock price data with a 'Date' column and a 'Close' column\n",
            "=========================================================================================================\n",
            "\n",
            "First, let's convert 'Date' to datetime type if it's not already\n",
            "================================================================\n",
            "\n",
            "df['Date'] = pd.to\\_datetime(df['Date'])\n",
            "\n",
            "Setting 'Date' as the index\n",
            "===========================\n",
            "\n",
            "df.set\\_index('Date', inplace=True)\n",
            "\n",
            "Let's say 'Close' is the column we want to predict\n",
            "==================================================\n",
            "\n",
            "For a time series forecasting model, we should split the data based on time\n",
            "===========================================================================\n",
            "\n",
            "split\\_date = '2023-01-01' # This is an example split date, adjust based on your dataset\n",
            "\n",
            "Splitting the data into train and test sets\n",
            "===========================================\n",
            "\n",
            "train = df.loc[df.index < split\\_date]\n",
            "test = df.loc[df.index >= split\\_date]\n",
            "\n",
            "For time series forecasting, it's common to use previous values as features\n",
            "===========================================================================\n",
            "\n",
            "Here, you can generate features based on your requirement, like lags of 'Close'\n",
            "===============================================================================\n",
            "\n",
            "For simplicity, we'll use only 'Close' as our feature to train the model\n",
            "========================================================================\n",
            "\n",
            "X\\_train, y\\_train = train[['Close']].values[:-1], train['Close'].values[1:]\n",
            "X\\_test, y\\_test = test[['Close']].values[:-1], test['Close'].values[1:]\n",
            "\n",
            "Initialize the AutoML instance\n",
            "==============================\n",
            "\n",
            "automl = AutoML()\n",
            "\n",
            "Specify the task as 'forecast' and set the time\\_budget. Adjust based on your needs.\n",
            "====================================================================================\n",
            "\n",
            "automl\\_settings = {\n",
            "\"time\\_budget\": 120, # Time budget in seconds\n",
            "\"metric\": 'mae', # Metric to optimize for. Adjust accordingly (e.g., 'mse' for Mean Squared Error)\n",
            "\"task\": 'forecast', # Specify the task type\n",
            "\"log\\_file\\_name\": \"stock\\_forecast.log\", # Log file\n",
            "}\n",
            "\n",
            "Start the AutoML run\n",
            "====================\n",
            "\n",
            "automl.fit(X\\_train=X\\_train, y\\_train=y\\_train, \\*\\*automl\\_settings)\n",
            "\n",
            "Predicting on the test set\n",
            "==========================\n",
            "\n",
            "y\\_pred = automl.predict(X\\_test)\n",
            "\n",
            "You can evaluate the predictions using your preferred metrics, such as MAE, MSE, etc.\n",
            "=====================================================================================\n",
            "\n",
            "```\n",
            "\n",
            "This script demonstrates how to use FLAML for time series forecasting with a focus on stock price prediction. Note that for more complex time series patterns and feature engineering, you may want to include additional steps for generating more informative features, handling seasonality and trends, and potentially transforming your target variable (e.g., using differencing to make the series stationary).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "from sklearn.model\\_selection import train\\_test\\_split\n",
            "import pandas as pd\n",
            "\n",
            "Assuming `df` is your DataFrame containing the stock price data with a 'Date' column and a 'Close' column\n",
            "=========================================================================================================\n",
            "\n",
            "First, let's convert 'Date' to datetime type if it's not already\n",
            "================================================================\n",
            "\n",
            "df['Date'] = pd.to\\_datetime(df['Date'])\n",
            "\n",
            "Setting 'Date' as the index\n",
            "===========================\n",
            "\n",
            "df.set\\_index('Date', inplace=True)\n",
            "\n",
            "Let's say 'Close' is the column we want to predict\n",
            "==================================================\n",
            "\n",
            "For a time series forecasting model, we should split the data based on time\n",
            "===========================================================================\n",
            "\n",
            "split\\_date = '2023-01-01' # This is an example split date, adjust based on your dataset\n",
            "\n",
            "Splitting the data into train and test sets\n",
            "===========================================\n",
            "\n",
            "train = df.loc[df.index < split\\_date]\n",
            "test = df.loc[df.index >= split\\_date]\n",
            "\n",
            "For time series forecasting, it's common to use previous values as features\n",
            "===========================================================================\n",
            "\n",
            "Here, you can generate features based on your requirement, like lags of 'Close'\n",
            "===============================================================================\n",
            "\n",
            "For simplicity, we'll use only 'Close' as our feature to train the model\n",
            "========================================================================\n",
            "\n",
            "X\\_train, y\\_train = train[['Close']].values[:-1], train['Close'].values[1:]\n",
            "X\\_test, y\\_test = test[['Close']].values[:-1], test['Close'].values[1:]\n",
            "\n",
            "Initialize the AutoML instance\n",
            "==============================\n",
            "\n",
            "automl = AutoML()\n",
            "\n",
            "Specify the task as 'forecast' and set the time\\_budget. Adjust based on your needs.\n",
            "====================================================================================\n",
            "\n",
            "automl\\_settings = {\n",
            "\"time\\_budget\": 120, # Time budget in seconds\n",
            "\"metric\": 'mae', # Metric to optimize for. Adjust accordingly (e.g., 'mse' for Mean Squared Error)\n",
            "\"task\": 'forecast', # Specify the task type\n",
            "\"log\\_file\\_name\": \"stock\\_forecast.log\", # Log file\n",
            "}\n",
            "\n",
            "Start the AutoML run\n",
            "====================\n",
            "\n",
            "automl.fit(X\\_train=X\\_train, y\\_train=y\\_train, \\*\\*automl\\_settings)\n",
            "\n",
            "Predicting on the test set\n",
            "==========================\n",
            "\n",
            "y\\_pred = automl.predict(X\\_test)\n",
            "\n",
            "You can evaluate the predictions using your preferred metrics, such as MAE, MSE, etc.\n",
            "=====================================================================================\n",
            "\n",
            "```\n",
            "\n",
            "This script demonstrates how to use FLAML for time series forecasting with a focus on stock price prediction. Note that for more complex time series patterns and feature engineering, you may want to include additional steps for generating more informative features, handling seasonality and trends, and potentially transforming your target variable (e.g., using differencing to make the series stationary).\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\n",
        "chat_result = ragproxyagent.initiate_chat(\n",
        "    assistant, message=ragproxyagent.message_generator, problem=code_problem, search_string=\"spark\"\n",
        ")  # search_st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDkDZoR-iBLb",
        "outputId": "ab82dcf6-b600-4ac8-9555-f3fba56c4089"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VectorDB returns doc_ids:  [['0d580ff7-7fc1-bf18-cd0c-de037cbd9343', '0ecd7192-3761-7d6f-9151-5ff504ca740b', '9be3ff7b-0243-32ab-5e97-7762580e2663']]\n",
            "Adding content of doc 0d580ff7-7fc1-bf18-cd0c-de037cbd9343 to context.\n",
            "Adding content of doc 0ecd7192-3761-7d6f-9151-5ff504ca740b to context.\n",
            "Adding content of doc 9be3ff7b-0243-32ab-5e97-7762580e2663 to context.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "For code generation, you must obey the following rules:\n",
            "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
            "Rule 2. You must follow the formats below to write your code:\n",
            "```language\n",
            "# your code\n",
            "```\n",
            "\n",
            "User's question is: How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\n",
            "\n",
            "Context is: [![PyPI version](https://badge.fury.io/py/FLAML.svg)](https://badge.fury.io/py/FLAML)\n",
            "![Conda version](https://img.shields.io/conda/vn/conda-forge/flaml)\n",
            "[![Build](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml/badge.svg)](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml)\n",
            "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/FLAML)](https://pypi.org/project/FLAML/)\n",
            "[![Downloads](https://pepy.tech/badge/flaml)](https://pepy.tech/project/flaml)\n",
            "[![](https://img.shields.io/discord/1025786666260111483?logo=discord&style=flat)](https://discord.gg/Cppx2vSPVP)\n",
            "\n",
            "<!-- [![Join the chat at https://gitter.im/FLAMLer/community](https://badges.gitter.im/FLAMLer/community.svg)](https://gitter.im/FLAMLer/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) -->\n",
            "\n",
            "# A Fast Library for Automated Machine Learning & Tuning\n",
            "\n",
            "<p align=\"center\">\n",
            "    <img src=\"https://github.com/microsoft/FLAML/blob/main/website/static/img/flaml.svg\"  width=200>\n",
            "    <br>\n",
            "</p>\n",
            "\n",
            ":fire: FLAML supports AutoML and Hyperparameter Tuning in [Microsoft Fabric Data Science](https://learn.microsoft.com/en-us/fabric/data-science/automated-machine-learning-fabric). In addition, we've introduced Python 3.11 support, along with a range of new estimators, and comprehensive integration with MLflow—thanks to contributions from the Microsoft Fabric product team.\n",
            "\n",
            ":fire: Heads-up: We have migrated [AutoGen](https://microsoft.github.io/autogen/) into a dedicated [github repository](https://github.com/microsoft/autogen). Alongside this move, we have also launched a dedicated [Discord](https://discord.gg/pAbnFJrkgZ) server and a [website](https://microsoft.github.io/autogen/) for comprehensive documentation.\n",
            "\n",
            ":fire: The automated multi-agent chat framework in [AutoGen](https://microsoft.github.io/autogen/) is in preview from v2.0.0.\n",
            "\n",
            ":fire: FLAML is highlighted in OpenAI's [cookbook](https://github.com/openai/openai-cookbook#related-resources-from-around-the-web).\n",
            "\n",
            ":fire: [autogen](https://microsoft.github.io/autogen/) is released with support for ChatGPT and GPT-4, based on [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673).\n",
            "\n",
            "## What is FLAML\n",
            "\n",
            "FLAML is a lightweight Python library for efficient automation of machine\n",
            "learning and AI operations. It automates workflow based on large language models, machine learning models, etc.\n",
            "and optimizes their performance.\n",
            "\n",
            "- FLAML enables building next-gen GPT-X applications based on multi-agent conversations with minimal effort. It simplifies the orchestration, automation and optimization of a complex GPT-X workflow. It maximizes the performance of GPT-X models and augments their weakness.\n",
            "- For common machine learning tasks like classification and regression, it quickly finds quality models for user-provided data with low computational resources. It is easy to customize or extend. Users can find their desired customizability from a smooth range.\n",
            "- It supports fast and economical automatic tuning (e.g., inference hyperparameters for foundation models, configurations in MLOps/LMOps workflows, pipelines, mathematical/statistical models, algorithms, computing experiments, software configurations), capable of handling large search space with heterogeneous evaluation cost and complex constraints/guidance/early stopping.\n",
            "\n",
            "FLAML is powered by a series of [research studies](https://microsoft.github.io/FLAML/docs/Research/) from Microsoft Research and collaborators such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.\n",
            "\n",
            "FLAML has a .NET implementation in [ML.NET](http://dot.net/ml), an open-source, cross-platform machine learning framework for .NET.\n",
            "\n",
            "## Installation\n",
            "\n",
            "FLAML requires **Python version >= 3.8**. It can be installed from pip:\n",
            "\n",
            "```bash\n",
            "pip install flaml\n",
            "```\n",
            "\n",
            "Minimal dependencies are installed without extra options. You can install extra options based on the feature you need. For example, use the following to install the dependencies needed by the [`autogen`](https://microsoft.github.io/autogen/) package.\n",
            "\n",
            "```bash\n",
            "pip install \"flaml[autogen]\"\n",
            "```\n",
            "\n",
            "Find more options in [Installation](https://microsoft.github.io/FLAML/docs/Installation).\n",
            "Each of the [`notebook examples`](https://github.com/microsoft/FLAML/tree/main/notebook) may require a specific option to be installed.\n",
            "\n",
            "## Quickstart\n",
            "\n",
            "- (New) The [autogen](https://microsoft.github.io/autogen/) package enables the next-gen GPT-X applications with a generic multi-agent conversation framework.\n",
            "  It offers customizable and conversable agents which integrate LLMs, tools and human.\n",
            "  By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code. For example,\n",
            "\n",
            "```python\n",
            "from flaml import autogen\n",
            "\n",
            "assistant = autogen.AssistantAgent(\"assistant\")\n",
            "user_proxy = autogen.UserProxyAgent(\"user_proxy\")\n",
            "user_proxy.initiate_chat(\n",
            "    assistant,\n",
            "    message=\"Show me the YTD gain of 10 largest technology companies as of today.\",\n",
            ")\n",
            "# This initiates an automated chat between the two agents to solve the task\n",
            "```\n",
            "\n",
            "Autogen also helps maximize the utility out of the expensive LLMs such as ChatGPT and GPT-4. It offers a drop-in replacement of `openai.Completion` or `openai.ChatCompletion` with powerful functionalites like tuning, caching, templating, filtering. For example, you can optimize generations by LLM with your own tuning data, success metrics and budgets.\n",
            "\n",
            "```python\n",
            "# perform tuning\n",
            "config, analysis = autogen.Completion.tune(\n",
            "    data=tune_data,\n",
            "    metric=\"success\",\n",
            "    mode=\"max\",\n",
            "    eval_func=eval_func,\n",
            "    inference_budget=0.05,\n",
            "    optimization_budget=3,\n",
            "    num_samples=-1,\n",
            ")\n",
            "# perform inference for a test instance\n",
            "response = autogen.Completion.create(context=test_instance, **config)\n",
            "```\n",
            "\n",
            "- With three lines of code, you can start using this economical and fast\n",
            "  AutoML engine as a [scikit-learn style estimator](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML).\n",
            "\n",
            "```python\n",
            "from flaml import AutoML\n",
            "\n",
            "automl = AutoML()\n",
            "automl.fit(X_train, y_train, task=\"classification\")\n",
            "```\n",
            "\n",
            "- You can restrict the learners and use FLAML as a fast hyperparameter tuning\n",
            "  tool for XGBoost, LightGBM, Random Forest etc. or a [customized learner](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#estimator-and-search-space).\n",
            "\n",
            "```python\n",
            "automl.fit(X_train, y_train, task=\"classification\", estimator_list=[\"lgbm\"])\n",
            "```\n",
            "\n",
            "- You can also run generic hyperparameter tuning for a [custom function](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function).\n",
            "\n",
            "```python\n",
            "from flaml import tune\n",
            "tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)\n",
            "```\n",
            "\n",
            "- [Zero-shot AutoML](https://microsoft.github.io/FLAML/docs/Use-Cases/Zero-Shot-AutoML) allows using the existing training API from lightgbm, xgboost etc. while getting the benefit of AutoML in choosing high-performance hyperparameter configurations per task.\n",
            "\n",
            "```python\n",
            "from flaml.default import LGBMRegressor\n",
            "\n",
            "# Use LGBMRegressor in the same way as you use lightgbm.LGBMRegressor.\n",
            "estimator = LGBMRegressor()\n",
            "# The hyperparameters are automatically set according to the training data.\n",
            "estimator.fit(X_train, y_train)\n",
            "```\n",
            "\n",
            "## Documentation\n",
            "\n",
            "You can find a detailed documentation about FLAML [here](https://microsoft.github.io/FLAML/).\n",
            "\n",
            "In addition, you can find:\n",
            "\n",
            "- [Research](https://microsoft.github.io/FLAML/docs/Research) and [blogposts](https://microsoft.github.io/FLAML/blog) around FLAML.\n",
            "\n",
            "- [Discord](https://discord.gg/Cppx2vSPVP).\n",
            "\n",
            "- [Contributing guide](https://microsoft.github.io/FLAML/docs/Contribute).\n",
            "\n",
            "- ML.NET documentation and tutorials for [Model Builder](https://learn.microsoft.com/dotnet/machine-learning/tutorials/predict-prices-with-model-builder), [ML.NET CLI](https://learn.microsoft.com/dotnet/machine-learning/tutorials/sentiment-analysis-cli), and [AutoML API](https://learn.microsoft.com/dotnet/machine-learning/how-to-guides/how-to-use-the-automl-api).\n",
            "\n",
            "## Contributing\n",
            "\n",
            "This project welcomes contributions and suggestions. Most contributions require you to agree to a\n",
            "Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n",
            "the rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\n",
            "# Research\n",
            "\n",
            "For technical details, please check our research publications.\n",
            "\n",
            "- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021flaml,\n",
            "    title={FLAML: A Fast and Lightweight AutoML Library},\n",
            "    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},\n",
            "    year={2021},\n",
            "    booktitle={MLSys},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021cfo,\n",
            "    title={Frugal Optimization for Cost-related Hyperparameters},\n",
            "    author={Qingyun Wu and Chi Wang and Silu Huang},\n",
            "    year={2021},\n",
            "    booktitle={AAAI},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2021blendsearch,\n",
            "    title={Economical Hyperparameter Optimization With Blended Search Strategy},\n",
            "    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},\n",
            "    year={2021},\n",
            "    booktitle={ICLR},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{liuwang2021hpolm,\n",
            "    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},\n",
            "    author={Susan Xueqing Liu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ACL},\n",
            "}\n",
            "```\n",
            "\n",
            "- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2021chacha,\n",
            "    title={ChaCha for Online AutoML},\n",
            "    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},\n",
            "    year={2021},\n",
            "    booktitle={ICML},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wuwang2021fairautoml,\n",
            "    title={Fair AutoML},\n",
            "    author={Qingyun Wu and Chi Wang},\n",
            "    year={2021},\n",
            "    booktitle={ArXiv preprint arXiv:2111.06495},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{kayaliwang2022default,\n",
            "    title={Mining Robust Default Configurations for Resource-constrained AutoML},\n",
            "    author={Moe Kayali and Chi Wang},\n",
            "    year={2022},\n",
            "    booktitle={ArXiv preprint arXiv:2202.09927},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{zhang2023targeted,\n",
            "    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},\n",
            "    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},\n",
            "    booktitle={International Conference on Learning Representations},\n",
            "    year={2023},\n",
            "    url={https://openreview.net/forum?id=0Ij9_q567Ma},\n",
            "}\n",
            "```\n",
            "\n",
            "- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wang2023EcoOptiGen,\n",
            "    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},\n",
            "    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2303.04673},\n",
            "}\n",
            "```\n",
            "\n",
            "- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n",
            "\n",
            "```bibtex\n",
            "@inproceedings{wu2023empirical,\n",
            "    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},\n",
            "    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},\n",
            "    year={2023},\n",
            "    booktitle={ArXiv preprint arXiv:2306.01337},\n",
            "}\n",
            "```\n",
            "If you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.\n",
            "\n",
            "When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n",
            "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n",
            "provided by the bot. You will only need to do this once across all repos using our CLA.\n",
            "\n",
            "This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n",
            "For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n",
            "contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
            "\n",
            "## Contributors Wall\n",
            "\n",
            "<a href=\"https://github.com/microsoft/flaml/graphs/contributors\">\n",
            "  <img src=\"https://contrib.rocks/image?repo=microsoft/flaml&max=204\" />\n",
            "</a>\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "Using FLAML for classification with parallel training via Spark and enforcing a time limit for the jobs requires combining FLAML's AutoML capabilities with Spark's distributed computing framework. However, FLAML does not natively support distributed training across Spark clusters directly as of the latest information available. To perform parallel training, you'd typically need to handle the distribution aspect separately, perhaps by distributing the cross-validation folds or training different models on different Spark executors. \n",
            "\n",
            "Here's a conceptual approach to achieve your objective, assuming you have a Spark environment set up and FLAML installed. This code does not directly run tasks in parallel across Spark but outlines how you might structure your code for a similar effect:\n",
            "\n",
            "1. **Setup Spark Session**: Ensure you have SparkSession created and configured according to your cluster setup.\n",
            "2. **Define FLAML Training Function**: This function will use FLAML to train a model given a dataset. You will use this function within Spark jobs.\n",
            "3. **Distribute Dataset**: If your dataset is large, ensure it's distributed appropriately and accessible to all Spark executors.\n",
            "4. **Parallel Jobs**: Kick off Spark jobs that each run FLAML independently with subsets of your data or different configurations. Use Spark's capabilities to manage these jobs, including timeouts.\n",
            "5. **Enforce Time Limit**: While Spark doesn't have a direct way to kill tasks after a certain time, you can manage job durations via the `timeout` parameter in Spark configurations or by manually monitoring job execution times and stopping them if they exceed your limits.\n",
            "\n",
            "Here's some skeleton Python code to illustrate parts of this approach:\n",
            "\n",
            "```python\n",
            "from pyspark.sql import SparkSession\n",
            "from flaml import AutoML\n",
            "import time\n",
            "\n",
            "# Initialize Spark Session\n",
            "spark = SparkSession.builder.appName(\"FLAML_Spark_Example\").getOrCreate()\n",
            "\n",
            "# Define a function to train a model with FLAML\n",
            "def train_model_with_flaml(data, time_budget=30):\n",
            "    automl = AutoML()\n",
            "    automl_settings = {\n",
            "        \"time_budget\": time_budget,  # Set the time budget for training\n",
            "        \"task\": 'classification',\n",
            "    }\n",
            "    automl.fit(data[0], data[1], **automl_settings)\n",
            "    return automl\n",
            "\n",
            "# Example function to create synthetic datasets (replace with your actual data loading)\n",
            "def get_synthetic_data_partition(index):\n",
            "    from sklearn.datasets import make_classification\n",
            "    X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=index)\n",
            "    return X, y\n",
            "\n",
            "# Example code to simulate parallel training (modify according to your actual Spark data handling)\n",
            "partitions = [get_synthetic_data_partition(i) for i in range(4)]  # Assume 4 partitions for illustration\n",
            "\n",
            "# Start model training in parallel, monitoring execution time\n",
            "start_time = time.time()\n",
            "models = spark.sparkContext.parallelize(partitions).map(train_model_with_flaml).collect()\n",
            "elapsed_time = time.time() - start_time\n",
            "\n",
            "print(f\"Training completed in {elapsed_time:.2f} seconds\")\n",
            "```\n",
            "\n",
            "Note: The above example doesn't directly implement Spark's ability to \"force cancel jobs if time limit is reached.\" To enforce hard timeouts on each training job, you would need to integrate more sophisticated job monitoring and management, potentially using Spark's task cancellation API or external job management tools. This level of control requires custom logic outside the standard FLAML and Spark APIs, potentially involving asynchronous programming or external job control mechanisms.\n",
            "\n",
            "Remember that FLAML is primarily designed for single-node operation, and achieving true parallelism with Spark requires careful management of data partitioning and resource allocation. For large-scale parallel training, consider using frameworks designed for distributed ML from the outset, like Apache Spark MLlib, Dask-ML, or distributed versions of TensorFlow or PyTorch.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as ragproxyagent. Provide feedback to assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "UPDATE CONTEXT\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as ragproxyagent. Provide feedback to assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.chat_history[-3]['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "dwWw28sHjgo7",
        "outputId": "74c8e85b-a211-4caa-a595-fdddab8e8973"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Using FLAML for classification with parallel training via Spark and enforcing a time limit for the jobs requires combining FLAML\\'s AutoML capabilities with Spark\\'s distributed computing framework. However, FLAML does not natively support distributed training across Spark clusters directly as of the latest information available. To perform parallel training, you\\'d typically need to handle the distribution aspect separately, perhaps by distributing the cross-validation folds or training different models on different Spark executors. \\n\\nHere\\'s a conceptual approach to achieve your objective, assuming you have a Spark environment set up and FLAML installed. This code does not directly run tasks in parallel across Spark but outlines how you might structure your code for a similar effect:\\n\\n1. **Setup Spark Session**: Ensure you have SparkSession created and configured according to your cluster setup.\\n2. **Define FLAML Training Function**: This function will use FLAML to train a model given a dataset. You will use this function within Spark jobs.\\n3. **Distribute Dataset**: If your dataset is large, ensure it\\'s distributed appropriately and accessible to all Spark executors.\\n4. **Parallel Jobs**: Kick off Spark jobs that each run FLAML independently with subsets of your data or different configurations. Use Spark\\'s capabilities to manage these jobs, including timeouts.\\n5. **Enforce Time Limit**: While Spark doesn\\'t have a direct way to kill tasks after a certain time, you can manage job durations via the `timeout` parameter in Spark configurations or by manually monitoring job execution times and stopping them if they exceed your limits.\\n\\nHere\\'s some skeleton Python code to illustrate parts of this approach:\\n\\n```python\\nfrom pyspark.sql import SparkSession\\nfrom flaml import AutoML\\nimport time\\n\\n# Initialize Spark Session\\nspark = SparkSession.builder.appName(\"FLAML_Spark_Example\").getOrCreate()\\n\\n# Define a function to train a model with FLAML\\ndef train_model_with_flaml(data, time_budget=30):\\n    automl = AutoML()\\n    automl_settings = {\\n        \"time_budget\": time_budget,  # Set the time budget for training\\n        \"task\": \\'classification\\',\\n    }\\n    automl.fit(data[0], data[1], **automl_settings)\\n    return automl\\n\\n# Example function to create synthetic datasets (replace with your actual data loading)\\ndef get_synthetic_data_partition(index):\\n    from sklearn.datasets import make_classification\\n    X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=index)\\n    return X, y\\n\\n# Example code to simulate parallel training (modify according to your actual Spark data handling)\\npartitions = [get_synthetic_data_partition(i) for i in range(4)]  # Assume 4 partitions for illustration\\n\\n# Start model training in parallel, monitoring execution time\\nstart_time = time.time()\\nmodels = spark.sparkContext.parallelize(partitions).map(train_model_with_flaml).collect()\\nelapsed_time = time.time() - start_time\\n\\nprint(f\"Training completed in {elapsed_time:.2f} seconds\")\\n```\\n\\nNote: The above example doesn\\'t directly implement Spark\\'s ability to \"force cancel jobs if time limit is reached.\" To enforce hard timeouts on each training job, you would need to integrate more sophisticated job monitoring and management, potentially using Spark\\'s task cancellation API or external job management tools. This level of control requires custom logic outside the standard FLAML and Spark APIs, potentially involving asynchronous programming or external job control mechanisms.\\n\\nRemember that FLAML is primarily designed for single-node operation, and achieving true parallelism with Spark requires careful management of data partitioning and resource allocation. For large-scale parallel training, consider using frameworks designed for distributed ML from the outset, like Apache Spark MLlib, Dask-ML, or distributed versions of TensorFlow or PyTorch.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggFSEPRRkGEF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}